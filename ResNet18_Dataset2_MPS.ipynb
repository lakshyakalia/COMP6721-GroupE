{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e03170d-dcff-4e10-a644-b950282e1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, Normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import os\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, f1_score\n",
    "from torchvision.transforms import v2\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f948234-20c4-49b2-8822-9c3a357b063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "\n",
    "#Model Parameters\n",
    "num_features = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ecf08e5-d742-45ed-b60a-c46351441114",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir=pathlib.Path(\"/Users/karthikd1054/Documents/COMP 6721/Project/plant_leaf_dataset/dataset2\")\n",
    "dataset = ImageFolder(root=\"/Users/karthikd1054/Documents/COMP 6721/Project/plant_leaf_dataset/dataset2\", transform=transforms.Compose([ToTensor(), transforms.Resize((224, 224))]))\n",
    "\n",
    "dataset_dict={\n",
    "    'Mango': list(dataset_dir.glob('Mango (P0)/*.JPG')),\n",
    "    'Arjun': list(dataset_dir.glob('Arjun (P1)/*.JPG')),\n",
    "    'Alstonia_Scholaris': list(dataset_dir.glob('Alstonia Scholaris (P2)/*.JPG')),\n",
    "    'Gauva': list(dataset_dir.glob('Gauva (P3)/*.JPG')),\n",
    "    'Jamun': list(dataset_dir.glob('Jamun (P5)/*.JPG')),\n",
    "    'Jatropha':list(dataset_dir.glob('Jatropha (P6)/*.JPG')),\n",
    "    'Pongamia_Pinnata':list(dataset_dir.glob('Pongamia Pinnata (P7)/*.JPG')),\n",
    "    'Basil':list(dataset_dir.glob('Basil (P8)/*.JPG')),\n",
    "    'Pomegranate':list(dataset_dir.glob('Pomegranate (P9)/*.JPG')),\n",
    "    'Lemon':list(dataset_dir.glob('Lemon (P10)/*.JPG')),\n",
    "    'Chinar':list(dataset_dir.glob('Chinar (P11)/*.JPG')),\n",
    "}\n",
    "\n",
    "class_label_dict={\n",
    "    'Mango':0,\n",
    "    'Arjun':1,\n",
    "    'Alstonia_Scholaris':2,\n",
    "    'Gauva':3,\n",
    "    'Jamun':4,\n",
    "    'Jatropha':5,\n",
    "    'Pongamia_Pinnata':6,\n",
    "    'Basil':7,\n",
    "    'Pomegranate':8,\n",
    "    'Lemon':9,\n",
    "    'Chinar':10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef36614-1d9a-4dea-8101-9c392e460e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images added to the list\n",
      "200 images added to the list\n",
      "300 images added to the list\n",
      "400 images added to the list\n",
      "500 images added to the list\n",
      "600 images added to the list\n",
      "700 images added to the list\n",
      "800 images added to the list\n",
      "900 images added to the list\n",
      "1000 images added to the list\n",
      "1100 images added to the list\n",
      "1200 images added to the list\n",
      "1300 images added to the list\n",
      "1400 images added to the list\n",
      "1500 images added to the list\n",
      "1600 images added to the list\n",
      "1700 images added to the list\n",
      "1800 images added to the list\n",
      "1900 images added to the list\n",
      "2000 images added to the list\n",
      "2100 images added to the list\n",
      "2200 images added to the list\n"
     ]
    }
   ],
   "source": [
    "affine_image = v2.Compose([\n",
    "    v2.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75)),\n",
    "])\n",
    "random_zoom=v2.Compose([\n",
    "    v2.RandomResizedCrop(size=(224, 224))\n",
    "])\n",
    "rotation=v2.Compose([\n",
    "    v2.RandomRotation(degrees=(0, 180))\n",
    "])\n",
    "auto_contrast=v2.Compose([\n",
    "  v2.RandomAutocontrast(0.5)\n",
    "])\n",
    "\n",
    "X=[]\n",
    "y=[]\n",
    "count=0\n",
    "for key in dataset_dict.keys():\n",
    "  for values in dataset_dict[key]:\n",
    "        resized_image=Image.open(values).resize((224,224))\n",
    "        X.append(resized_image)\n",
    "        y.append(class_label_dict[key])\n",
    "        affined_image=affine_image(resized_image)\n",
    "        X.append(affined_image)\n",
    "        y.append(class_label_dict[key])\n",
    "        zoomed_image=random_zoom(resized_image)\n",
    "        X.append(zoomed_image)\n",
    "        y.append(class_label_dict[key])\n",
    "        rotated_image=rotation(resized_image)\n",
    "        X.append(rotated_image)\n",
    "        y.append(class_label_dict[key])\n",
    "        contrast_image=auto_contrast(resized_image)\n",
    "        X.append(contrast_image)\n",
    "        y.append(class_label_dict[key])\n",
    "        count+=1\n",
    "        if (count%100==0):\n",
    "          print(f\"{count} images added to the list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d97744dd-cc1a-4308-ac1f-d74048c94098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the dataset ready for taining out of x_train and y_train\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define your transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.2572, 0.2816, 0.2473],\n",
    "                         std=[0.3007, 0.3072, 0.2996])\n",
    "])\n",
    "\n",
    "# Create your Dataset\n",
    "dataset = CustomDataset(images=X, labels=y, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af2afa0d-2cad-4aff-b7ed-6e354237aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, testDataset=torch.utils.data.random_split(dataset, [int(0.9 * len(dataset)), len(dataset) - (int(0.9 * len(dataset)))])\n",
    "trainDataset, validationDataset = torch.utils.data.random_split(dataset, [int(0.9 * len(dataset)), len(dataset) - (int(0.9 * len(dataset)))])\n",
    "\n",
    "\n",
    "\n",
    "trainingDataLoader = DataLoader(\n",
    "    trainDataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validationDataLoader = DataLoader(\n",
    "    validationDataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "testingDataLoader = DataLoader(\n",
    "    testDataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "#Write code to display the images in each dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3174e414-a18b-4fbb-b918-509568b3b263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=11, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(weights=None)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_features)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3a30437-3595-47ad-a15b-b8cef9629a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90c69a11-0c0d-4960-ab57-0ccb74930373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [1/289], Loss: 2.5090880, Accuracy: 6.2500%\n",
      "Epoch [1/20], Step [11/289], Loss: 2.1663809, Accuracy: 25.0000%\n",
      "Epoch [1/20], Step [21/289], Loss: 2.1284118, Accuracy: 28.1250%\n",
      "Epoch [1/20], Step [31/289], Loss: 2.0642288, Accuracy: 25.0000%\n",
      "Epoch [1/20], Step [41/289], Loss: 1.8553276, Accuracy: 28.1250%\n",
      "Epoch [1/20], Step [51/289], Loss: 1.9646220, Accuracy: 31.2500%\n",
      "Epoch [1/20], Step [61/289], Loss: 1.8610511, Accuracy: 28.1250%\n",
      "Epoch [1/20], Step [71/289], Loss: 1.7610285, Accuracy: 50.0000%\n",
      "Epoch [1/20], Step [81/289], Loss: 1.6827750, Accuracy: 43.7500%\n",
      "Epoch [1/20], Step [91/289], Loss: 1.7745663, Accuracy: 31.2500%\n",
      "Epoch [1/20], Step [101/289], Loss: 1.4219956, Accuracy: 59.3750%\n",
      "Epoch [1/20], Step [111/289], Loss: 1.6706611, Accuracy: 43.7500%\n",
      "Epoch [1/20], Step [121/289], Loss: 1.4761039, Accuracy: 46.8750%\n",
      "Epoch [1/20], Step [131/289], Loss: 1.9444249, Accuracy: 37.5000%\n",
      "Epoch [1/20], Step [141/289], Loss: 1.3520240, Accuracy: 59.3750%\n",
      "Epoch [1/20], Step [151/289], Loss: 1.6461930, Accuracy: 46.8750%\n",
      "Epoch [1/20], Step [161/289], Loss: 1.2096803, Accuracy: 59.3750%\n",
      "Epoch [1/20], Step [171/289], Loss: 1.5107533, Accuracy: 50.0000%\n",
      "Epoch [1/20], Step [181/289], Loss: 1.1110988, Accuracy: 71.8750%\n",
      "Epoch [1/20], Step [191/289], Loss: 1.4428924, Accuracy: 40.6250%\n",
      "Epoch [1/20], Step [201/289], Loss: 1.2667512, Accuracy: 59.3750%\n",
      "Epoch [1/20], Step [211/289], Loss: 1.6677240, Accuracy: 46.8750%\n",
      "Epoch [1/20], Step [221/289], Loss: 1.1024381, Accuracy: 56.2500%\n",
      "Epoch [1/20], Step [231/289], Loss: 1.0397010, Accuracy: 65.6250%\n",
      "Epoch [1/20], Step [241/289], Loss: 1.3188219, Accuracy: 53.1250%\n",
      "Epoch [1/20], Step [251/289], Loss: 1.2852391, Accuracy: 68.7500%\n",
      "Epoch [1/20], Step [261/289], Loss: 0.9766942, Accuracy: 68.7500%\n",
      "Epoch [1/20], Step [271/289], Loss: 0.9771326, Accuracy: 71.8750%\n",
      "Epoch [1/20], Step [281/289], Loss: 1.3667111, Accuracy: 56.2500%\n",
      "EPOCH 1.....................\n",
      "Accuracy on training set: 48.281097494848716%\n",
      "Accuracy on validation set: 53.5609756097561%\n",
      "Epoch [2/20], Step [1/289], Loss: 1.2814341, Accuracy: 56.2500%\n",
      "Epoch [2/20], Step [11/289], Loss: 1.0398753, Accuracy: 71.8750%\n",
      "Epoch [2/20], Step [21/289], Loss: 1.2851727, Accuracy: 56.2500%\n",
      "Epoch [2/20], Step [31/289], Loss: 0.9349146, Accuracy: 75.0000%\n",
      "Epoch [2/20], Step [41/289], Loss: 1.0615543, Accuracy: 65.6250%\n",
      "Epoch [2/20], Step [51/289], Loss: 1.2751811, Accuracy: 56.2500%\n",
      "Epoch [2/20], Step [61/289], Loss: 0.8287411, Accuracy: 78.1250%\n",
      "Epoch [2/20], Step [71/289], Loss: 1.0468153, Accuracy: 68.7500%\n",
      "Epoch [2/20], Step [81/289], Loss: 1.0477533, Accuracy: 65.6250%\n",
      "Epoch [2/20], Step [91/289], Loss: 1.2633617, Accuracy: 62.5000%\n",
      "Epoch [2/20], Step [101/289], Loss: 0.7321659, Accuracy: 75.0000%\n",
      "Epoch [2/20], Step [111/289], Loss: 0.9763728, Accuracy: 68.7500%\n",
      "Epoch [2/20], Step [121/289], Loss: 1.2407742, Accuracy: 50.0000%\n",
      "Epoch [2/20], Step [131/289], Loss: 1.3163819, Accuracy: 53.1250%\n",
      "Epoch [2/20], Step [141/289], Loss: 0.7905791, Accuracy: 78.1250%\n",
      "Epoch [2/20], Step [151/289], Loss: 0.7217266, Accuracy: 78.1250%\n",
      "Epoch [2/20], Step [161/289], Loss: 1.2374949, Accuracy: 59.3750%\n",
      "Epoch [2/20], Step [171/289], Loss: 0.8838910, Accuracy: 68.7500%\n",
      "Epoch [2/20], Step [181/289], Loss: 0.8276692, Accuracy: 68.7500%\n",
      "Epoch [2/20], Step [191/289], Loss: 1.1894478, Accuracy: 53.1250%\n",
      "Epoch [2/20], Step [201/289], Loss: 0.6678547, Accuracy: 65.6250%\n",
      "Epoch [2/20], Step [211/289], Loss: 1.0168227, Accuracy: 62.5000%\n",
      "Epoch [2/20], Step [221/289], Loss: 1.0054078, Accuracy: 71.8750%\n",
      "Epoch [2/20], Step [231/289], Loss: 0.9711320, Accuracy: 65.6250%\n",
      "Epoch [2/20], Step [241/289], Loss: 0.6653938, Accuracy: 84.3750%\n",
      "Epoch [2/20], Step [251/289], Loss: 0.8942136, Accuracy: 68.7500%\n",
      "Epoch [2/20], Step [261/289], Loss: 0.6093045, Accuracy: 87.5000%\n",
      "Epoch [2/20], Step [271/289], Loss: 0.5856855, Accuracy: 81.2500%\n",
      "Epoch [2/20], Step [281/289], Loss: 0.7740655, Accuracy: 78.1250%\n",
      "EPOCH 2.....................\n",
      "Accuracy on training set: 70.54549398113002%\n",
      "Accuracy on validation set: 63.41463414634146%\n",
      "Epoch [3/20], Step [1/289], Loss: 0.7933667, Accuracy: 75.0000%\n",
      "Epoch [3/20], Step [11/289], Loss: 0.6802270, Accuracy: 68.7500%\n",
      "Epoch [3/20], Step [21/289], Loss: 1.0349318, Accuracy: 78.1250%\n",
      "Epoch [3/20], Step [31/289], Loss: 0.6623257, Accuracy: 68.7500%\n",
      "Epoch [3/20], Step [41/289], Loss: 0.8079872, Accuracy: 59.3750%\n",
      "Epoch [3/20], Step [51/289], Loss: 0.4954278, Accuracy: 81.2500%\n",
      "Epoch [3/20], Step [61/289], Loss: 0.7368572, Accuracy: 75.0000%\n",
      "Epoch [3/20], Step [71/289], Loss: 0.6679914, Accuracy: 78.1250%\n",
      "Epoch [3/20], Step [81/289], Loss: 0.6297325, Accuracy: 87.5000%\n",
      "Epoch [3/20], Step [91/289], Loss: 0.5992908, Accuracy: 78.1250%\n",
      "Epoch [3/20], Step [101/289], Loss: 0.3348053, Accuracy: 93.7500%\n",
      "Epoch [3/20], Step [111/289], Loss: 0.6072220, Accuracy: 78.1250%\n",
      "Epoch [3/20], Step [121/289], Loss: 0.6407266, Accuracy: 75.0000%\n",
      "Epoch [3/20], Step [131/289], Loss: 0.7215649, Accuracy: 84.3750%\n",
      "Epoch [3/20], Step [141/289], Loss: 0.5128413, Accuracy: 81.2500%\n",
      "Epoch [3/20], Step [151/289], Loss: 0.8194624, Accuracy: 75.0000%\n",
      "Epoch [3/20], Step [161/289], Loss: 0.9021366, Accuracy: 71.8750%\n",
      "Epoch [3/20], Step [171/289], Loss: 0.9422010, Accuracy: 65.6250%\n",
      "Epoch [3/20], Step [181/289], Loss: 0.8261431, Accuracy: 65.6250%\n",
      "Epoch [3/20], Step [191/289], Loss: 0.5796800, Accuracy: 78.1250%\n",
      "Epoch [3/20], Step [201/289], Loss: 0.6386297, Accuracy: 75.0000%\n",
      "Epoch [3/20], Step [211/289], Loss: 0.3795502, Accuracy: 84.3750%\n",
      "Epoch [3/20], Step [221/289], Loss: 0.6023096, Accuracy: 81.2500%\n",
      "Epoch [3/20], Step [231/289], Loss: 0.6415749, Accuracy: 84.3750%\n",
      "Epoch [3/20], Step [241/289], Loss: 0.6090173, Accuracy: 90.6250%\n",
      "Epoch [3/20], Step [251/289], Loss: 0.8196635, Accuracy: 75.0000%\n",
      "Epoch [3/20], Step [261/289], Loss: 0.3943061, Accuracy: 81.2500%\n",
      "Epoch [3/20], Step [271/289], Loss: 0.7079471, Accuracy: 78.1250%\n",
      "Epoch [3/20], Step [281/289], Loss: 0.4927944, Accuracy: 84.3750%\n",
      "EPOCH 3.....................\n",
      "Accuracy on training set: 79.69851426092615%\n",
      "Accuracy on validation set: 30.829268292682926%\n",
      "Epoch [4/20], Step [1/289], Loss: 0.9306743, Accuracy: 68.7500%\n",
      "Epoch [4/20], Step [11/289], Loss: 0.3664004, Accuracy: 90.6250%\n",
      "Epoch [4/20], Step [21/289], Loss: 0.4277149, Accuracy: 87.5000%\n",
      "Epoch [4/20], Step [31/289], Loss: 0.5815125, Accuracy: 81.2500%\n",
      "Epoch [4/20], Step [41/289], Loss: 0.5865035, Accuracy: 71.8750%\n",
      "Epoch [4/20], Step [51/289], Loss: 0.3524143, Accuracy: 84.3750%\n",
      "Epoch [4/20], Step [61/289], Loss: 0.5416816, Accuracy: 84.3750%\n",
      "Epoch [4/20], Step [71/289], Loss: 0.4336274, Accuracy: 87.5000%\n",
      "Epoch [4/20], Step [81/289], Loss: 0.8934472, Accuracy: 68.7500%\n",
      "Epoch [4/20], Step [91/289], Loss: 0.5458191, Accuracy: 84.3750%\n",
      "Epoch [4/20], Step [101/289], Loss: 0.5327344, Accuracy: 81.2500%\n",
      "Epoch [4/20], Step [111/289], Loss: 0.3931933, Accuracy: 81.2500%\n",
      "Epoch [4/20], Step [121/289], Loss: 0.3073160, Accuracy: 96.8750%\n",
      "Epoch [4/20], Step [131/289], Loss: 0.5775480, Accuracy: 78.1250%\n",
      "Epoch [4/20], Step [141/289], Loss: 0.5143824, Accuracy: 87.5000%\n",
      "Epoch [4/20], Step [151/289], Loss: 0.2530638, Accuracy: 93.7500%\n",
      "Epoch [4/20], Step [161/289], Loss: 0.5552180, Accuracy: 90.6250%\n",
      "Epoch [4/20], Step [171/289], Loss: 0.6523619, Accuracy: 81.2500%\n",
      "Epoch [4/20], Step [181/289], Loss: 0.5283769, Accuracy: 81.2500%\n",
      "Epoch [4/20], Step [191/289], Loss: 0.6152135, Accuracy: 78.1250%\n",
      "Epoch [4/20], Step [201/289], Loss: 0.4802795, Accuracy: 84.3750%\n",
      "Epoch [4/20], Step [211/289], Loss: 0.5547374, Accuracy: 84.3750%\n",
      "Epoch [4/20], Step [221/289], Loss: 0.5339729, Accuracy: 84.3750%\n",
      "Epoch [4/20], Step [231/289], Loss: 0.5092645, Accuracy: 87.5000%\n",
      "Epoch [4/20], Step [241/289], Loss: 0.5510503, Accuracy: 84.3750%\n",
      "Epoch [4/20], Step [251/289], Loss: 0.6211948, Accuracy: 84.3750%\n",
      "Epoch [4/20], Step [261/289], Loss: 0.8010523, Accuracy: 75.0000%\n",
      "Epoch [4/20], Step [271/289], Loss: 0.4004476, Accuracy: 84.3750%\n",
      "Epoch [4/20], Step [281/289], Loss: 0.4538558, Accuracy: 84.3750%\n",
      "EPOCH 4.....................\n",
      "Accuracy on training set: 82.81097494848714%\n",
      "Accuracy on validation set: 49.170731707317074%\n",
      "Epoch [5/20], Step [1/289], Loss: 0.8892558, Accuracy: 68.7500%\n",
      "Epoch [5/20], Step [11/289], Loss: 0.3225091, Accuracy: 87.5000%\n",
      "Epoch [5/20], Step [21/289], Loss: 0.3461179, Accuracy: 90.6250%\n",
      "Epoch [5/20], Step [31/289], Loss: 0.5654534, Accuracy: 78.1250%\n",
      "Epoch [5/20], Step [41/289], Loss: 0.3159136, Accuracy: 90.6250%\n",
      "Epoch [5/20], Step [51/289], Loss: 0.6205435, Accuracy: 78.1250%\n",
      "Epoch [5/20], Step [61/289], Loss: 0.3522270, Accuracy: 90.6250%\n",
      "Epoch [5/20], Step [71/289], Loss: 0.3825809, Accuracy: 93.7500%\n",
      "Epoch [5/20], Step [81/289], Loss: 0.4484391, Accuracy: 87.5000%\n",
      "Epoch [5/20], Step [91/289], Loss: 0.6838328, Accuracy: 78.1250%\n",
      "Epoch [5/20], Step [101/289], Loss: 0.4150838, Accuracy: 78.1250%\n",
      "Epoch [5/20], Step [111/289], Loss: 0.2129438, Accuracy: 93.7500%\n",
      "Epoch [5/20], Step [121/289], Loss: 0.5434272, Accuracy: 78.1250%\n",
      "Epoch [5/20], Step [131/289], Loss: 0.4893096, Accuracy: 81.2500%\n",
      "Epoch [5/20], Step [141/289], Loss: 0.4261049, Accuracy: 84.3750%\n",
      "Epoch [5/20], Step [151/289], Loss: 0.4619210, Accuracy: 84.3750%\n",
      "Epoch [5/20], Step [161/289], Loss: 0.2694945, Accuracy: 90.6250%\n",
      "Epoch [5/20], Step [171/289], Loss: 0.2758896, Accuracy: 93.7500%\n",
      "Epoch [5/20], Step [181/289], Loss: 0.3552693, Accuracy: 84.3750%\n",
      "Epoch [5/20], Step [191/289], Loss: 0.1439970, Accuracy: 96.8750%\n",
      "Epoch [5/20], Step [201/289], Loss: 0.3780712, Accuracy: 87.5000%\n",
      "Epoch [5/20], Step [211/289], Loss: 0.3580663, Accuracy: 84.3750%\n",
      "Epoch [5/20], Step [221/289], Loss: 0.3753334, Accuracy: 90.6250%\n",
      "Epoch [5/20], Step [231/289], Loss: 0.4238902, Accuracy: 81.2500%\n",
      "Epoch [5/20], Step [241/289], Loss: 0.3115761, Accuracy: 93.7500%\n",
      "Epoch [5/20], Step [251/289], Loss: 0.2310088, Accuracy: 93.7500%\n",
      "Epoch [5/20], Step [261/289], Loss: 0.2373577, Accuracy: 90.6250%\n",
      "Epoch [5/20], Step [271/289], Loss: 0.4969370, Accuracy: 87.5000%\n",
      "Epoch [5/20], Step [281/289], Loss: 0.2976686, Accuracy: 87.5000%\n",
      "EPOCH 5.....................\n",
      "Accuracy on training set: 87.6152261143043%\n",
      "Accuracy on validation set: 68.78048780487805%\n",
      "Epoch [6/20], Step [1/289], Loss: 0.9086304, Accuracy: 78.1250%\n",
      "Epoch [6/20], Step [11/289], Loss: 0.4243200, Accuracy: 87.5000%\n",
      "Epoch [6/20], Step [21/289], Loss: 0.4944320, Accuracy: 78.1250%\n",
      "Epoch [6/20], Step [31/289], Loss: 0.2489194, Accuracy: 93.7500%\n",
      "Epoch [6/20], Step [41/289], Loss: 0.2795675, Accuracy: 90.6250%\n",
      "Epoch [6/20], Step [51/289], Loss: 0.1851102, Accuracy: 93.7500%\n",
      "Epoch [6/20], Step [61/289], Loss: 0.3328485, Accuracy: 87.5000%\n",
      "Epoch [6/20], Step [71/289], Loss: 0.2148648, Accuracy: 93.7500%\n",
      "Epoch [6/20], Step [81/289], Loss: 0.3997695, Accuracy: 90.6250%\n",
      "Epoch [6/20], Step [91/289], Loss: 0.4468962, Accuracy: 90.6250%\n",
      "Epoch [6/20], Step [101/289], Loss: 0.2683067, Accuracy: 90.6250%\n",
      "Epoch [6/20], Step [111/289], Loss: 0.2629241, Accuracy: 90.6250%\n",
      "Epoch [6/20], Step [121/289], Loss: 0.4518679, Accuracy: 87.5000%\n",
      "Epoch [6/20], Step [131/289], Loss: 0.4475294, Accuracy: 87.5000%\n",
      "Epoch [6/20], Step [141/289], Loss: 0.4328492, Accuracy: 78.1250%\n",
      "Epoch [6/20], Step [151/289], Loss: 0.2761284, Accuracy: 90.6250%\n",
      "Epoch [6/20], Step [161/289], Loss: 0.2806597, Accuracy: 90.6250%\n",
      "Epoch [6/20], Step [171/289], Loss: 0.2290080, Accuracy: 93.7500%\n",
      "Epoch [6/20], Step [181/289], Loss: 0.4764310, Accuracy: 87.5000%\n",
      "Epoch [6/20], Step [191/289], Loss: 0.5242870, Accuracy: 84.3750%\n",
      "Epoch [6/20], Step [201/289], Loss: 0.3206434, Accuracy: 90.6250%\n",
      "Epoch [6/20], Step [211/289], Loss: 0.4797475, Accuracy: 87.5000%\n",
      "Epoch [6/20], Step [221/289], Loss: 0.2759776, Accuracy: 93.7500%\n",
      "Epoch [6/20], Step [231/289], Loss: 0.3606155, Accuracy: 93.7500%\n",
      "Epoch [6/20], Step [241/289], Loss: 0.2735194, Accuracy: 90.6250%\n",
      "Epoch [6/20], Step [251/289], Loss: 0.3923794, Accuracy: 87.5000%\n",
      "Epoch [6/20], Step [261/289], Loss: 0.1971089, Accuracy: 93.7500%\n",
      "Epoch [6/20], Step [271/289], Loss: 0.1457488, Accuracy: 96.8750%\n",
      "Epoch [6/20], Step [281/289], Loss: 0.6153122, Accuracy: 81.2500%\n",
      "EPOCH 6.....................\n",
      "Accuracy on training set: 89.27448216028631%\n",
      "Accuracy on validation set: 30.926829268292682%\n",
      "Epoch [7/20], Step [1/289], Loss: 0.7580978, Accuracy: 71.8750%\n",
      "Epoch [7/20], Step [11/289], Loss: 0.3752074, Accuracy: 87.5000%\n",
      "Epoch [7/20], Step [21/289], Loss: 0.1038512, Accuracy: 96.8750%\n",
      "Epoch [7/20], Step [31/289], Loss: 0.2004826, Accuracy: 93.7500%\n",
      "Epoch [7/20], Step [41/289], Loss: 0.0733926, Accuracy: 100.0000%\n",
      "Epoch [7/20], Step [51/289], Loss: 0.3793035, Accuracy: 93.7500%\n",
      "Epoch [7/20], Step [61/289], Loss: 0.1820983, Accuracy: 96.8750%\n",
      "Epoch [7/20], Step [71/289], Loss: 0.4189088, Accuracy: 87.5000%\n",
      "Epoch [7/20], Step [81/289], Loss: 0.0712671, Accuracy: 100.0000%\n",
      "Epoch [7/20], Step [91/289], Loss: 0.1239660, Accuracy: 96.8750%\n",
      "Epoch [7/20], Step [101/289], Loss: 0.2278589, Accuracy: 93.7500%\n",
      "Epoch [7/20], Step [111/289], Loss: 0.1941442, Accuracy: 96.8750%\n",
      "Epoch [7/20], Step [121/289], Loss: 0.3046688, Accuracy: 87.5000%\n",
      "Epoch [7/20], Step [131/289], Loss: 0.4267923, Accuracy: 90.6250%\n",
      "Epoch [7/20], Step [141/289], Loss: 0.3807639, Accuracy: 84.3750%\n",
      "Epoch [7/20], Step [151/289], Loss: 0.2015132, Accuracy: 93.7500%\n",
      "Epoch [7/20], Step [161/289], Loss: 0.2417748, Accuracy: 96.8750%\n",
      "Epoch [7/20], Step [171/289], Loss: 0.3980075, Accuracy: 78.1250%\n",
      "Epoch [7/20], Step [181/289], Loss: 0.1745144, Accuracy: 93.7500%\n",
      "Epoch [7/20], Step [191/289], Loss: 0.4103067, Accuracy: 87.5000%\n",
      "Epoch [7/20], Step [201/289], Loss: 0.1967104, Accuracy: 93.7500%\n",
      "Epoch [7/20], Step [211/289], Loss: 0.2077376, Accuracy: 93.7500%\n",
      "Epoch [7/20], Step [221/289], Loss: 0.1654126, Accuracy: 96.8750%\n",
      "Epoch [7/20], Step [231/289], Loss: 0.4710063, Accuracy: 84.3750%\n",
      "Epoch [7/20], Step [241/289], Loss: 0.1769460, Accuracy: 93.7500%\n",
      "Epoch [7/20], Step [251/289], Loss: 0.0783453, Accuracy: 100.0000%\n",
      "Epoch [7/20], Step [261/289], Loss: 0.2185157, Accuracy: 96.8750%\n",
      "Epoch [7/20], Step [271/289], Loss: 0.1141175, Accuracy: 96.8750%\n",
      "Epoch [7/20], Step [281/289], Loss: 0.4236743, Accuracy: 90.6250%\n",
      "EPOCH 7.....................\n",
      "Accuracy on training set: 90.84697972020388%\n",
      "Accuracy on validation set: 49.65853658536585%\n",
      "Epoch [8/20], Step [1/289], Loss: 1.1175052, Accuracy: 75.0000%\n",
      "Epoch [8/20], Step [11/289], Loss: 0.2384217, Accuracy: 96.8750%\n",
      "Epoch [8/20], Step [21/289], Loss: 0.1692602, Accuracy: 96.8750%\n",
      "Epoch [8/20], Step [31/289], Loss: 0.3974479, Accuracy: 87.5000%\n",
      "Epoch [8/20], Step [41/289], Loss: 0.3133937, Accuracy: 87.5000%\n",
      "Epoch [8/20], Step [51/289], Loss: 0.4912841, Accuracy: 84.3750%\n",
      "Epoch [8/20], Step [61/289], Loss: 0.2502049, Accuracy: 87.5000%\n",
      "Epoch [8/20], Step [71/289], Loss: 0.2563101, Accuracy: 90.6250%\n",
      "Epoch [8/20], Step [81/289], Loss: 0.1667412, Accuracy: 90.6250%\n",
      "Epoch [8/20], Step [91/289], Loss: 0.3004644, Accuracy: 87.5000%\n",
      "Epoch [8/20], Step [101/289], Loss: 0.1600188, Accuracy: 93.7500%\n",
      "Epoch [8/20], Step [111/289], Loss: 0.4211514, Accuracy: 87.5000%\n",
      "Epoch [8/20], Step [121/289], Loss: 0.3690102, Accuracy: 81.2500%\n",
      "Epoch [8/20], Step [131/289], Loss: 0.2074926, Accuracy: 93.7500%\n",
      "Epoch [8/20], Step [141/289], Loss: 0.2826659, Accuracy: 90.6250%\n",
      "Epoch [8/20], Step [151/289], Loss: 0.1355288, Accuracy: 96.8750%\n",
      "Epoch [8/20], Step [161/289], Loss: 0.2040212, Accuracy: 93.7500%\n",
      "Epoch [8/20], Step [171/289], Loss: 0.1441164, Accuracy: 100.0000%\n",
      "Epoch [8/20], Step [181/289], Loss: 0.1728418, Accuracy: 96.8750%\n",
      "Epoch [8/20], Step [191/289], Loss: 0.5024776, Accuracy: 78.1250%\n",
      "Epoch [8/20], Step [201/289], Loss: 0.3931357, Accuracy: 84.3750%\n",
      "Epoch [8/20], Step [211/289], Loss: 0.3010180, Accuracy: 90.6250%\n",
      "Epoch [8/20], Step [221/289], Loss: 0.3641914, Accuracy: 90.6250%\n",
      "Epoch [8/20], Step [231/289], Loss: 0.2906471, Accuracy: 87.5000%\n",
      "Epoch [8/20], Step [241/289], Loss: 0.4698978, Accuracy: 81.2500%\n",
      "Epoch [8/20], Step [251/289], Loss: 0.1354825, Accuracy: 93.7500%\n",
      "Epoch [8/20], Step [261/289], Loss: 0.1861837, Accuracy: 96.8750%\n",
      "Epoch [8/20], Step [271/289], Loss: 0.2023532, Accuracy: 90.6250%\n",
      "Epoch [8/20], Step [281/289], Loss: 0.0998837, Accuracy: 100.0000%\n",
      "EPOCH 8.....................\n",
      "Accuracy on training set: 92.321873983299%\n",
      "Accuracy on validation set: 60.8780487804878%\n",
      "Epoch [9/20], Step [1/289], Loss: 0.4458294, Accuracy: 84.3750%\n",
      "Epoch [9/20], Step [11/289], Loss: 0.1016721, Accuracy: 100.0000%\n",
      "Epoch [9/20], Step [21/289], Loss: 0.3732468, Accuracy: 84.3750%\n",
      "Epoch [9/20], Step [31/289], Loss: 0.1005582, Accuracy: 96.8750%\n",
      "Epoch [9/20], Step [41/289], Loss: 0.1515191, Accuracy: 96.8750%\n",
      "Epoch [9/20], Step [51/289], Loss: 0.2581726, Accuracy: 87.5000%\n",
      "Epoch [9/20], Step [61/289], Loss: 0.2413136, Accuracy: 90.6250%\n",
      "Epoch [9/20], Step [71/289], Loss: 0.1867805, Accuracy: 90.6250%\n",
      "Epoch [9/20], Step [81/289], Loss: 0.1810915, Accuracy: 93.7500%\n",
      "Epoch [9/20], Step [91/289], Loss: 0.1393083, Accuracy: 96.8750%\n",
      "Epoch [9/20], Step [101/289], Loss: 0.3609269, Accuracy: 84.3750%\n",
      "Epoch [9/20], Step [111/289], Loss: 0.3323396, Accuracy: 87.5000%\n",
      "Epoch [9/20], Step [121/289], Loss: 0.3544993, Accuracy: 87.5000%\n",
      "Epoch [9/20], Step [131/289], Loss: 0.4216372, Accuracy: 90.6250%\n",
      "Epoch [9/20], Step [141/289], Loss: 0.3528631, Accuracy: 90.6250%\n",
      "Epoch [9/20], Step [151/289], Loss: 0.1862226, Accuracy: 96.8750%\n",
      "Epoch [9/20], Step [161/289], Loss: 0.2365460, Accuracy: 93.7500%\n",
      "Epoch [9/20], Step [171/289], Loss: 0.2177219, Accuracy: 90.6250%\n",
      "Epoch [9/20], Step [181/289], Loss: 0.1654920, Accuracy: 96.8750%\n",
      "Epoch [9/20], Step [191/289], Loss: 0.1737841, Accuracy: 93.7500%\n",
      "Epoch [9/20], Step [201/289], Loss: 0.0595923, Accuracy: 100.0000%\n",
      "Epoch [9/20], Step [211/289], Loss: 0.3131728, Accuracy: 93.7500%\n",
      "Epoch [9/20], Step [221/289], Loss: 0.1692258, Accuracy: 93.7500%\n",
      "Epoch [9/20], Step [231/289], Loss: 0.0934893, Accuracy: 96.8750%\n",
      "Epoch [9/20], Step [241/289], Loss: 0.2331834, Accuracy: 93.7500%\n",
      "Epoch [9/20], Step [251/289], Loss: 0.1486421, Accuracy: 93.7500%\n",
      "Epoch [9/20], Step [261/289], Loss: 0.1730314, Accuracy: 93.7500%\n",
      "Epoch [9/20], Step [271/289], Loss: 0.0685150, Accuracy: 100.0000%\n",
      "Epoch [9/20], Step [281/289], Loss: 0.3494958, Accuracy: 90.6250%\n",
      "EPOCH 9.....................\n",
      "Accuracy on training set: 93.76423381411995%\n",
      "Accuracy on validation set: 19.804878048780488%\n",
      "Epoch [10/20], Step [1/289], Loss: 2.8989041, Accuracy: 50.0000%\n",
      "Epoch [10/20], Step [11/289], Loss: 0.2931626, Accuracy: 93.7500%\n",
      "Epoch [10/20], Step [21/289], Loss: 0.2154776, Accuracy: 96.8750%\n",
      "Epoch [10/20], Step [31/289], Loss: 0.1093381, Accuracy: 96.8750%\n",
      "Epoch [10/20], Step [41/289], Loss: 0.0597765, Accuracy: 100.0000%\n",
      "Epoch [10/20], Step [51/289], Loss: 0.0588459, Accuracy: 100.0000%\n",
      "Epoch [10/20], Step [61/289], Loss: 0.1447287, Accuracy: 93.7500%\n",
      "Epoch [10/20], Step [71/289], Loss: 0.1876287, Accuracy: 96.8750%\n",
      "Epoch [10/20], Step [81/289], Loss: 0.0726727, Accuracy: 96.8750%\n",
      "Epoch [10/20], Step [91/289], Loss: 0.2047423, Accuracy: 90.6250%\n",
      "Epoch [10/20], Step [101/289], Loss: 0.1810415, Accuracy: 93.7500%\n",
      "Epoch [10/20], Step [111/289], Loss: 0.2990395, Accuracy: 90.6250%\n",
      "Epoch [10/20], Step [121/289], Loss: 0.1272964, Accuracy: 93.7500%\n",
      "Epoch [10/20], Step [131/289], Loss: 0.2943847, Accuracy: 93.7500%\n",
      "Epoch [10/20], Step [141/289], Loss: 0.1155043, Accuracy: 96.8750%\n",
      "Epoch [10/20], Step [151/289], Loss: 0.0964151, Accuracy: 100.0000%\n",
      "Epoch [10/20], Step [161/289], Loss: 0.1081273, Accuracy: 93.7500%\n",
      "Epoch [10/20], Step [171/289], Loss: 0.0998314, Accuracy: 96.8750%\n",
      "Epoch [10/20], Step [181/289], Loss: 0.0846742, Accuracy: 100.0000%\n",
      "Epoch [10/20], Step [191/289], Loss: 0.1917534, Accuracy: 93.7500%\n",
      "Epoch [10/20], Step [201/289], Loss: 0.2715311, Accuracy: 90.6250%\n",
      "Epoch [10/20], Step [211/289], Loss: 0.0520888, Accuracy: 100.0000%\n",
      "Epoch [10/20], Step [221/289], Loss: 0.1744928, Accuracy: 96.8750%\n",
      "Epoch [10/20], Step [231/289], Loss: 0.0484437, Accuracy: 100.0000%\n",
      "Epoch [10/20], Step [241/289], Loss: 0.1257014, Accuracy: 96.8750%\n",
      "Epoch [10/20], Step [251/289], Loss: 0.6417595, Accuracy: 84.3750%\n",
      "Epoch [10/20], Step [261/289], Loss: 0.3491311, Accuracy: 87.5000%\n",
      "Epoch [10/20], Step [271/289], Loss: 0.0724106, Accuracy: 96.8750%\n",
      "Epoch [10/20], Step [281/289], Loss: 0.1947627, Accuracy: 96.8750%\n",
      "EPOCH 10.....................\n",
      "Accuracy on training set: 93.8401474894263%\n",
      "Accuracy on validation set: 82.34146341463415%\n",
      "Epoch [11/20], Step [1/289], Loss: 0.4152405, Accuracy: 81.2500%\n",
      "Epoch [11/20], Step [11/289], Loss: 0.1262944, Accuracy: 96.8750%\n",
      "Epoch [11/20], Step [21/289], Loss: 0.1872426, Accuracy: 90.6250%\n",
      "Epoch [11/20], Step [31/289], Loss: 0.4919524, Accuracy: 84.3750%\n",
      "Epoch [11/20], Step [41/289], Loss: 0.1788259, Accuracy: 96.8750%\n",
      "Epoch [11/20], Step [51/289], Loss: 0.1207508, Accuracy: 96.8750%\n",
      "Epoch [11/20], Step [61/289], Loss: 0.2638760, Accuracy: 90.6250%\n",
      "Epoch [11/20], Step [71/289], Loss: 0.1765188, Accuracy: 93.7500%\n",
      "Epoch [11/20], Step [81/289], Loss: 0.2057202, Accuracy: 90.6250%\n",
      "Epoch [11/20], Step [91/289], Loss: 0.2576431, Accuracy: 93.7500%\n",
      "Epoch [11/20], Step [101/289], Loss: 0.2221159, Accuracy: 90.6250%\n",
      "Epoch [11/20], Step [111/289], Loss: 0.1578308, Accuracy: 93.7500%\n",
      "Epoch [11/20], Step [121/289], Loss: 0.2756041, Accuracy: 90.6250%\n",
      "Epoch [11/20], Step [131/289], Loss: 0.0520407, Accuracy: 100.0000%\n",
      "Epoch [11/20], Step [141/289], Loss: 0.1842746, Accuracy: 93.7500%\n",
      "Epoch [11/20], Step [151/289], Loss: 0.2615364, Accuracy: 90.6250%\n",
      "Epoch [11/20], Step [161/289], Loss: 0.0862663, Accuracy: 96.8750%\n",
      "Epoch [11/20], Step [171/289], Loss: 0.0286641, Accuracy: 100.0000%\n",
      "Epoch [11/20], Step [181/289], Loss: 0.0686166, Accuracy: 100.0000%\n",
      "Epoch [11/20], Step [191/289], Loss: 0.2842532, Accuracy: 93.7500%\n",
      "Epoch [11/20], Step [201/289], Loss: 0.4350603, Accuracy: 87.5000%\n",
      "Epoch [11/20], Step [211/289], Loss: 0.1032433, Accuracy: 96.8750%\n",
      "Epoch [11/20], Step [221/289], Loss: 0.1655228, Accuracy: 90.6250%\n",
      "Epoch [11/20], Step [231/289], Loss: 0.3103482, Accuracy: 93.7500%\n",
      "Epoch [11/20], Step [241/289], Loss: 0.0457437, Accuracy: 100.0000%\n",
      "Epoch [11/20], Step [251/289], Loss: 0.1003868, Accuracy: 96.8750%\n",
      "Epoch [11/20], Step [261/289], Loss: 0.0547122, Accuracy: 100.0000%\n",
      "Epoch [11/20], Step [271/289], Loss: 0.0745387, Accuracy: 100.0000%\n",
      "Epoch [11/20], Step [281/289], Loss: 0.0309400, Accuracy: 100.0000%\n",
      "EPOCH 11.....................\n",
      "Accuracy on training set: 94.77280121461881%\n",
      "Accuracy on validation set: 92.29268292682927%\n",
      "Epoch [12/20], Step [1/289], Loss: 0.0393279, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [11/289], Loss: 0.1176247, Accuracy: 96.8750%\n",
      "Epoch [12/20], Step [21/289], Loss: 0.0431936, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [31/289], Loss: 0.1879425, Accuracy: 87.5000%\n",
      "Epoch [12/20], Step [41/289], Loss: 0.2349744, Accuracy: 93.7500%\n",
      "Epoch [12/20], Step [51/289], Loss: 0.0797507, Accuracy: 96.8750%\n",
      "Epoch [12/20], Step [61/289], Loss: 0.0476113, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [71/289], Loss: 0.2645102, Accuracy: 87.5000%\n",
      "Epoch [12/20], Step [81/289], Loss: 0.0420046, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [91/289], Loss: 0.0862349, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [101/289], Loss: 0.0501301, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [111/289], Loss: 0.1104766, Accuracy: 96.8750%\n",
      "Epoch [12/20], Step [121/289], Loss: 0.0513724, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [131/289], Loss: 0.0396341, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [141/289], Loss: 0.1529168, Accuracy: 93.7500%\n",
      "Epoch [12/20], Step [151/289], Loss: 0.2798280, Accuracy: 93.7500%\n",
      "Epoch [12/20], Step [161/289], Loss: 0.0575377, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [171/289], Loss: 0.0848730, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [181/289], Loss: 0.0470750, Accuracy: 96.8750%\n",
      "Epoch [12/20], Step [191/289], Loss: 0.2484600, Accuracy: 93.7500%\n",
      "Epoch [12/20], Step [201/289], Loss: 0.0703435, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [211/289], Loss: 0.0412832, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [221/289], Loss: 0.0835147, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [231/289], Loss: 0.1193317, Accuracy: 96.8750%\n",
      "Epoch [12/20], Step [241/289], Loss: 0.0329478, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [251/289], Loss: 0.0442639, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [261/289], Loss: 0.1084096, Accuracy: 93.7500%\n",
      "Epoch [12/20], Step [271/289], Loss: 0.1009178, Accuracy: 100.0000%\n",
      "Epoch [12/20], Step [281/289], Loss: 0.0301829, Accuracy: 100.0000%\n",
      "EPOCH 12.....................\n",
      "Accuracy on training set: 96.3886780175686%\n",
      "Accuracy on validation set: 79.31707317073172%\n",
      "Epoch [13/20], Step [1/289], Loss: 0.5419505, Accuracy: 87.5000%\n",
      "Epoch [13/20], Step [11/289], Loss: 0.2938684, Accuracy: 93.7500%\n",
      "Epoch [13/20], Step [21/289], Loss: 0.1492808, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [31/289], Loss: 0.2267508, Accuracy: 93.7500%\n",
      "Epoch [13/20], Step [41/289], Loss: 0.1687802, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [51/289], Loss: 0.0169315, Accuracy: 100.0000%\n",
      "Epoch [13/20], Step [61/289], Loss: 0.2637618, Accuracy: 93.7500%\n",
      "Epoch [13/20], Step [71/289], Loss: 0.1235010, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [81/289], Loss: 0.0682435, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [91/289], Loss: 0.3903539, Accuracy: 87.5000%\n",
      "Epoch [13/20], Step [101/289], Loss: 0.0288593, Accuracy: 100.0000%\n",
      "Epoch [13/20], Step [111/289], Loss: 0.1399192, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [121/289], Loss: 0.1123563, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [131/289], Loss: 0.0489169, Accuracy: 100.0000%\n",
      "Epoch [13/20], Step [141/289], Loss: 0.2438683, Accuracy: 93.7500%\n",
      "Epoch [13/20], Step [151/289], Loss: 0.1082315, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [161/289], Loss: 0.0688267, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [171/289], Loss: 0.0904950, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [181/289], Loss: 0.0498614, Accuracy: 100.0000%\n",
      "Epoch [13/20], Step [191/289], Loss: 0.0953647, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [201/289], Loss: 0.1231908, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [211/289], Loss: 0.1479731, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [221/289], Loss: 0.1011025, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [231/289], Loss: 0.0905961, Accuracy: 93.7500%\n",
      "Epoch [13/20], Step [241/289], Loss: 0.0793104, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [251/289], Loss: 0.1047547, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [261/289], Loss: 0.0939497, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [271/289], Loss: 0.0760741, Accuracy: 96.8750%\n",
      "Epoch [13/20], Step [281/289], Loss: 0.0131379, Accuracy: 100.0000%\n",
      "EPOCH 13.....................\n",
      "Accuracy on training set: 96.26938509923002%\n",
      "Accuracy on validation set: 92.97560975609757%\n",
      "Epoch [14/20], Step [1/289], Loss: 0.0642276, Accuracy: 96.8750%\n",
      "Epoch [14/20], Step [11/289], Loss: 0.0918215, Accuracy: 96.8750%\n",
      "Epoch [14/20], Step [21/289], Loss: 0.3359408, Accuracy: 87.5000%\n",
      "Epoch [14/20], Step [31/289], Loss: 0.0407652, Accuracy: 100.0000%\n",
      "Epoch [14/20], Step [41/289], Loss: 0.2447553, Accuracy: 90.6250%\n",
      "Epoch [14/20], Step [51/289], Loss: 0.1472988, Accuracy: 93.7500%\n",
      "Epoch [14/20], Step [61/289], Loss: 0.0708874, Accuracy: 100.0000%\n",
      "Epoch [14/20], Step [71/289], Loss: 0.0264026, Accuracy: 100.0000%\n",
      "Epoch [14/20], Step [81/289], Loss: 0.2357726, Accuracy: 90.6250%\n",
      "Epoch [14/20], Step [91/289], Loss: 0.1526721, Accuracy: 96.8750%\n",
      "Epoch [14/20], Step [101/289], Loss: 0.0850710, Accuracy: 100.0000%\n",
      "Epoch [14/20], Step [111/289], Loss: 0.0996659, Accuracy: 93.7500%\n",
      "Epoch [14/20], Step [121/289], Loss: 0.2137731, Accuracy: 84.3750%\n",
      "Epoch [14/20], Step [131/289], Loss: 0.0305788, Accuracy: 100.0000%\n",
      "Epoch [14/20], Step [141/289], Loss: 0.1472559, Accuracy: 90.6250%\n",
      "Epoch [14/20], Step [151/289], Loss: 0.0853958, Accuracy: 96.8750%\n",
      "Epoch [14/20], Step [161/289], Loss: 0.2149463, Accuracy: 93.7500%\n",
      "Epoch [14/20], Step [171/289], Loss: 0.0241425, Accuracy: 100.0000%\n",
      "Epoch [14/20], Step [181/289], Loss: 0.2166371, Accuracy: 90.6250%\n",
      "Epoch [14/20], Step [191/289], Loss: 0.0148965, Accuracy: 100.0000%\n",
      "Epoch [14/20], Step [201/289], Loss: 0.2017977, Accuracy: 93.7500%\n",
      "Epoch [14/20], Step [211/289], Loss: 0.0247718, Accuracy: 100.0000%\n",
      "Epoch [14/20], Step [221/289], Loss: 0.0664998, Accuracy: 96.8750%\n",
      "Epoch [14/20], Step [231/289], Loss: 0.0620182, Accuracy: 100.0000%\n",
      "Epoch [14/20], Step [241/289], Loss: 0.0905979, Accuracy: 96.8750%\n",
      "Epoch [14/20], Step [251/289], Loss: 0.2104928, Accuracy: 93.7500%\n",
      "Epoch [14/20], Step [261/289], Loss: 0.1245449, Accuracy: 96.8750%\n",
      "Epoch [14/20], Step [271/289], Loss: 0.1065983, Accuracy: 96.8750%\n",
      "Epoch [14/20], Step [281/289], Loss: 0.0889212, Accuracy: 96.8750%\n",
      "EPOCH 14.....................\n",
      "Accuracy on training set: 96.95260817698731%\n",
      "Accuracy on validation set: 96.39024390243902%\n",
      "Epoch [15/20], Step [1/289], Loss: 0.0619847, Accuracy: 100.0000%\n",
      "Epoch [15/20], Step [11/289], Loss: 0.1057788, Accuracy: 96.8750%\n",
      "Epoch [15/20], Step [21/289], Loss: 0.1682532, Accuracy: 96.8750%\n",
      "Epoch [15/20], Step [31/289], Loss: 0.0447314, Accuracy: 100.0000%\n",
      "Epoch [15/20], Step [41/289], Loss: 0.1611748, Accuracy: 93.7500%\n",
      "Epoch [15/20], Step [51/289], Loss: 0.0380555, Accuracy: 100.0000%\n",
      "Epoch [15/20], Step [61/289], Loss: 0.0345692, Accuracy: 100.0000%\n",
      "Epoch [15/20], Step [71/289], Loss: 0.0639715, Accuracy: 96.8750%\n",
      "Epoch [15/20], Step [81/289], Loss: 0.0351355, Accuracy: 100.0000%\n",
      "Epoch [15/20], Step [91/289], Loss: 0.1018726, Accuracy: 96.8750%\n",
      "Epoch [15/20], Step [101/289], Loss: 0.2683196, Accuracy: 93.7500%\n",
      "Epoch [15/20], Step [111/289], Loss: 0.1513536, Accuracy: 93.7500%\n",
      "Epoch [15/20], Step [121/289], Loss: 0.2393982, Accuracy: 90.6250%\n",
      "Epoch [15/20], Step [131/289], Loss: 0.0399558, Accuracy: 100.0000%\n",
      "Epoch [15/20], Step [141/289], Loss: 0.0615931, Accuracy: 100.0000%\n",
      "Epoch [15/20], Step [151/289], Loss: 0.0924896, Accuracy: 96.8750%\n",
      "Epoch [15/20], Step [161/289], Loss: 0.0280048, Accuracy: 100.0000%\n",
      "Epoch [15/20], Step [171/289], Loss: 0.1311167, Accuracy: 96.8750%\n",
      "Epoch [15/20], Step [181/289], Loss: 0.0428207, Accuracy: 100.0000%\n",
      "Epoch [15/20], Step [191/289], Loss: 0.0993242, Accuracy: 96.8750%\n",
      "Epoch [15/20], Step [201/289], Loss: 0.0644879, Accuracy: 96.8750%\n",
      "Epoch [15/20], Step [211/289], Loss: 0.0498967, Accuracy: 100.0000%\n",
      "Epoch [15/20], Step [221/289], Loss: 0.1053624, Accuracy: 96.8750%\n",
      "Epoch [15/20], Step [231/289], Loss: 0.1696784, Accuracy: 90.6250%\n",
      "Epoch [15/20], Step [241/289], Loss: 0.0465307, Accuracy: 96.8750%\n",
      "Epoch [15/20], Step [251/289], Loss: 0.1034902, Accuracy: 100.0000%\n",
      "Epoch [15/20], Step [261/289], Loss: 0.1084474, Accuracy: 93.7500%\n",
      "Epoch [15/20], Step [271/289], Loss: 0.1390770, Accuracy: 96.8750%\n",
      "Epoch [15/20], Step [281/289], Loss: 0.0609262, Accuracy: 100.0000%\n",
      "EPOCH 15.....................\n",
      "Accuracy on training set: 97.47315909337382%\n",
      "Accuracy on validation set: 95.80487804878048%\n",
      "Epoch [16/20], Step [1/289], Loss: 0.0084474, Accuracy: 100.0000%\n",
      "Epoch [16/20], Step [11/289], Loss: 0.1575908, Accuracy: 90.6250%\n",
      "Epoch [16/20], Step [21/289], Loss: 0.0103945, Accuracy: 100.0000%\n",
      "Epoch [16/20], Step [31/289], Loss: 0.0718162, Accuracy: 96.8750%\n",
      "Epoch [16/20], Step [41/289], Loss: 0.0569936, Accuracy: 100.0000%\n",
      "Epoch [16/20], Step [51/289], Loss: 0.0155082, Accuracy: 100.0000%\n",
      "Epoch [16/20], Step [61/289], Loss: 0.0528746, Accuracy: 100.0000%\n",
      "Epoch [16/20], Step [71/289], Loss: 0.0687822, Accuracy: 96.8750%\n",
      "Epoch [16/20], Step [81/289], Loss: 0.1150254, Accuracy: 96.8750%\n",
      "Epoch [16/20], Step [91/289], Loss: 0.1185175, Accuracy: 93.7500%\n",
      "Epoch [16/20], Step [101/289], Loss: 0.2632650, Accuracy: 93.7500%\n",
      "Epoch [16/20], Step [111/289], Loss: 0.0399471, Accuracy: 100.0000%\n",
      "Epoch [16/20], Step [121/289], Loss: 0.0505811, Accuracy: 100.0000%\n",
      "Epoch [16/20], Step [131/289], Loss: 0.0440920, Accuracy: 96.8750%\n",
      "Epoch [16/20], Step [141/289], Loss: 0.0493407, Accuracy: 100.0000%\n",
      "Epoch [16/20], Step [151/289], Loss: 0.1362268, Accuracy: 93.7500%\n",
      "Epoch [16/20], Step [161/289], Loss: 0.0186735, Accuracy: 100.0000%\n",
      "Epoch [16/20], Step [171/289], Loss: 0.1446607, Accuracy: 93.7500%\n",
      "Epoch [16/20], Step [181/289], Loss: 0.0474890, Accuracy: 100.0000%\n",
      "Epoch [16/20], Step [191/289], Loss: 0.0845132, Accuracy: 96.8750%\n",
      "Epoch [16/20], Step [201/289], Loss: 0.0272359, Accuracy: 100.0000%\n",
      "Epoch [16/20], Step [211/289], Loss: 0.0494050, Accuracy: 96.8750%\n",
      "Epoch [16/20], Step [221/289], Loss: 0.1187507, Accuracy: 96.8750%\n",
      "Epoch [16/20], Step [231/289], Loss: 0.1448592, Accuracy: 96.8750%\n",
      "Epoch [16/20], Step [241/289], Loss: 0.0170465, Accuracy: 100.0000%\n",
      "Epoch [16/20], Step [251/289], Loss: 0.0887280, Accuracy: 96.8750%\n",
      "Epoch [16/20], Step [261/289], Loss: 0.0161140, Accuracy: 100.0000%\n",
      "Epoch [16/20], Step [271/289], Loss: 0.1046163, Accuracy: 93.7500%\n",
      "Epoch [16/20], Step [281/289], Loss: 0.0899024, Accuracy: 96.8750%\n",
      "EPOCH 16.....................\n",
      "Accuracy on training set: 97.71174493005097%\n",
      "Accuracy on validation set: 64.19512195121952%\n",
      "Epoch [17/20], Step [1/289], Loss: 0.1897380, Accuracy: 96.8750%\n",
      "Epoch [17/20], Step [11/289], Loss: 0.1400015, Accuracy: 93.7500%\n",
      "Epoch [17/20], Step [21/289], Loss: 0.4895465, Accuracy: 87.5000%\n",
      "Epoch [17/20], Step [31/289], Loss: 0.0269552, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [41/289], Loss: 0.0720752, Accuracy: 96.8750%\n",
      "Epoch [17/20], Step [51/289], Loss: 0.0353202, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [61/289], Loss: 0.0227859, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [71/289], Loss: 0.0470774, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [81/289], Loss: 0.2407557, Accuracy: 96.8750%\n",
      "Epoch [17/20], Step [91/289], Loss: 0.0365214, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [101/289], Loss: 0.0139425, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [111/289], Loss: 0.0571302, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [121/289], Loss: 0.0273233, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [131/289], Loss: 0.0448325, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [141/289], Loss: 0.0825031, Accuracy: 96.8750%\n",
      "Epoch [17/20], Step [151/289], Loss: 0.0345203, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [161/289], Loss: 0.0535717, Accuracy: 96.8750%\n",
      "Epoch [17/20], Step [171/289], Loss: 0.1269149, Accuracy: 96.8750%\n",
      "Epoch [17/20], Step [181/289], Loss: 0.1319415, Accuracy: 96.8750%\n",
      "Epoch [17/20], Step [191/289], Loss: 0.0326246, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [201/289], Loss: 0.0465116, Accuracy: 96.8750%\n",
      "Epoch [17/20], Step [211/289], Loss: 0.0427274, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [221/289], Loss: 0.0389014, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [231/289], Loss: 0.0940097, Accuracy: 96.8750%\n",
      "Epoch [17/20], Step [241/289], Loss: 0.0359690, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [251/289], Loss: 0.1365602, Accuracy: 96.8750%\n",
      "Epoch [17/20], Step [261/289], Loss: 0.0486342, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [271/289], Loss: 0.0189049, Accuracy: 100.0000%\n",
      "Epoch [17/20], Step [281/289], Loss: 0.0585039, Accuracy: 96.8750%\n",
      "EPOCH 17.....................\n",
      "Accuracy on training set: 98.12384773885697%\n",
      "Accuracy on validation set: 95.70731707317073%\n",
      "Epoch [18/20], Step [1/289], Loss: 0.0779986, Accuracy: 96.8750%\n",
      "Epoch [18/20], Step [11/289], Loss: 0.0238237, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [21/289], Loss: 0.0293273, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [31/289], Loss: 0.0639925, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [41/289], Loss: 0.0645893, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [51/289], Loss: 0.0211078, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [61/289], Loss: 0.0309497, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [71/289], Loss: 0.0548984, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [81/289], Loss: 0.0805969, Accuracy: 96.8750%\n",
      "Epoch [18/20], Step [91/289], Loss: 0.0514829, Accuracy: 96.8750%\n",
      "Epoch [18/20], Step [101/289], Loss: 0.0531213, Accuracy: 96.8750%\n",
      "Epoch [18/20], Step [111/289], Loss: 0.0175992, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [121/289], Loss: 0.0319733, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [131/289], Loss: 0.0078476, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [141/289], Loss: 0.1472765, Accuracy: 93.7500%\n",
      "Epoch [18/20], Step [151/289], Loss: 0.0553989, Accuracy: 96.8750%\n",
      "Epoch [18/20], Step [161/289], Loss: 0.0178095, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [171/289], Loss: 0.0314402, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [181/289], Loss: 0.0194443, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [191/289], Loss: 0.0063014, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [201/289], Loss: 0.0093920, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [211/289], Loss: 0.0888206, Accuracy: 93.7500%\n",
      "Epoch [18/20], Step [221/289], Loss: 0.0349639, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [231/289], Loss: 0.1055030, Accuracy: 96.8750%\n",
      "Epoch [18/20], Step [241/289], Loss: 0.0265728, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [251/289], Loss: 0.0165427, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [261/289], Loss: 0.0197829, Accuracy: 100.0000%\n",
      "Epoch [18/20], Step [271/289], Loss: 0.1998304, Accuracy: 96.8750%\n",
      "Epoch [18/20], Step [281/289], Loss: 0.2751568, Accuracy: 90.6250%\n",
      "EPOCH 18.....................\n",
      "Accuracy on training set: 98.6335538444854%\n",
      "Accuracy on validation set: 96.48780487804878%\n",
      "Epoch [19/20], Step [1/289], Loss: 0.0508318, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [11/289], Loss: 0.0220935, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [21/289], Loss: 0.0749499, Accuracy: 96.8750%\n",
      "Epoch [19/20], Step [31/289], Loss: 0.0171841, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [41/289], Loss: 0.0103541, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [51/289], Loss: 0.0212499, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [61/289], Loss: 0.0181781, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [71/289], Loss: 0.0454615, Accuracy: 96.8750%\n",
      "Epoch [19/20], Step [81/289], Loss: 0.0166759, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [91/289], Loss: 0.0434188, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [101/289], Loss: 0.0162832, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [111/289], Loss: 0.0957520, Accuracy: 96.8750%\n",
      "Epoch [19/20], Step [121/289], Loss: 0.0321743, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [131/289], Loss: 0.0537436, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [141/289], Loss: 0.1220677, Accuracy: 90.6250%\n",
      "Epoch [19/20], Step [151/289], Loss: 0.0195755, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [161/289], Loss: 0.2823647, Accuracy: 87.5000%\n",
      "Epoch [19/20], Step [171/289], Loss: 0.1183589, Accuracy: 96.8750%\n",
      "Epoch [19/20], Step [181/289], Loss: 0.0230854, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [191/289], Loss: 0.1864144, Accuracy: 93.7500%\n",
      "Epoch [19/20], Step [201/289], Loss: 0.0344825, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [211/289], Loss: 0.0304714, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [221/289], Loss: 0.0451081, Accuracy: 96.8750%\n",
      "Epoch [19/20], Step [231/289], Loss: 0.0396766, Accuracy: 96.8750%\n",
      "Epoch [19/20], Step [241/289], Loss: 0.1088511, Accuracy: 93.7500%\n",
      "Epoch [19/20], Step [251/289], Loss: 0.0108553, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [261/289], Loss: 0.0421009, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [271/289], Loss: 0.0100805, Accuracy: 100.0000%\n",
      "Epoch [19/20], Step [281/289], Loss: 0.0142652, Accuracy: 100.0000%\n",
      "EPOCH 19.....................\n",
      "Accuracy on training set: 98.39496800780826%\n",
      "Accuracy on validation set: 96.39024390243902%\n",
      "Epoch [20/20], Step [1/289], Loss: 0.0243565, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [11/289], Loss: 0.0948745, Accuracy: 93.7500%\n",
      "Epoch [20/20], Step [21/289], Loss: 0.0806921, Accuracy: 96.8750%\n",
      "Epoch [20/20], Step [31/289], Loss: 0.0927612, Accuracy: 96.8750%\n",
      "Epoch [20/20], Step [41/289], Loss: 0.0909623, Accuracy: 93.7500%\n",
      "Epoch [20/20], Step [51/289], Loss: 0.0132069, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [61/289], Loss: 0.0046843, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [71/289], Loss: 0.0122235, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [81/289], Loss: 0.0259354, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [91/289], Loss: 0.1078528, Accuracy: 96.8750%\n",
      "Epoch [20/20], Step [101/289], Loss: 0.0100698, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [111/289], Loss: 0.0038716, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [121/289], Loss: 0.0646613, Accuracy: 96.8750%\n",
      "Epoch [20/20], Step [131/289], Loss: 0.0172885, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [141/289], Loss: 0.0503344, Accuracy: 96.8750%\n",
      "Epoch [20/20], Step [151/289], Loss: 0.1003954, Accuracy: 96.8750%\n",
      "Epoch [20/20], Step [161/289], Loss: 0.0889865, Accuracy: 93.7500%\n",
      "Epoch [20/20], Step [171/289], Loss: 0.0123265, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [181/289], Loss: 0.0242408, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [191/289], Loss: 0.0789484, Accuracy: 96.8750%\n",
      "Epoch [20/20], Step [201/289], Loss: 0.0349155, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [211/289], Loss: 0.0247588, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [221/289], Loss: 0.0291298, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [231/289], Loss: 0.0060937, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [241/289], Loss: 0.0261113, Accuracy: 100.0000%\n",
      "Epoch [20/20], Step [251/289], Loss: 0.1712742, Accuracy: 96.8750%\n",
      "Epoch [20/20], Step [261/289], Loss: 0.1214323, Accuracy: 93.7500%\n",
      "Epoch [20/20], Step [271/289], Loss: 0.0579491, Accuracy: 96.8750%\n",
      "Epoch [20/20], Step [281/289], Loss: 0.0585141, Accuracy: 96.8750%\n",
      "EPOCH 20.....................\n",
      "Accuracy on training set: 98.70946751979179%\n",
      "Accuracy on validation set: 96.39024390243902%\n",
      "Training Finished!\n"
     ]
    }
   ],
   "source": [
    "total_steps = len(trainingDataLoader)\n",
    "\n",
    "batchwiseTrainAccuracyLog = []\n",
    "batchwiseTrainLossLog = []\n",
    "\n",
    "epochwiseTrainAccuracyLog = []\n",
    "epochwiseTrainLossLog = []\n",
    "\n",
    "batchwiseValAccuracyLog = []\n",
    "batchwiseValLossLog = []\n",
    "\n",
    "epochwiseValAccuracyLog = []\n",
    "epochwiseValLossLog = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    total_label_count = 0\n",
    "\n",
    "    accumulated_train_loss=0\n",
    "    accumulated_validation_loss=0\n",
    "\n",
    "    accumulated_train_accuracy=0\n",
    "    accumulated_validation_accuracy=0\n",
    "\n",
    "    inner_loop_counter_train=0\n",
    "    model.train()\n",
    "    for i, data in enumerate(trainingDataLoader):\n",
    "        inner_loop_counter_train+=1\n",
    "\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backprop and optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Train accuracy\n",
    "        total = labels.size(0)\n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        total_label_count += labels.size(0)\n",
    "        accumulated_train_accuracy += (predicted == labels).sum().item()\n",
    "        accumulated_train_loss+=loss.item()\n",
    "        if (i + 10) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.7f}, Accuracy: {:.4f}%'\n",
    "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
    "                    (correct / total) * 100))\n",
    "            batchwiseTrainAccuracyLog.append((correct / total) * 100)\n",
    "            batchwiseTrainLossLog.append(loss.item())\n",
    "    training_accuracy = accumulated_train_accuracy / total_label_count\n",
    "    epochwiseTrainAccuracyLog.append(training_accuracy)\n",
    "    print(f'EPOCH {epoch + 1}.....................')\n",
    "    print('Accuracy on training set: {}%'.format(100 * training_accuracy))\n",
    "    epochwiseTrainLossLog.append(accumulated_train_loss/inner_loop_counter_train)\n",
    "\n",
    "    #Evaluation using validation data\n",
    "\n",
    "    total_label_count = 0\n",
    "\n",
    "    inner_loop_counter_validation=0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(validationDataLoader):\n",
    "        inner_loop_counter_validation+=1\n",
    "\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total = labels.size(0)\n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accumulated_validation_accuracy += (predicted == labels).sum().item()\n",
    "        total_label_count += labels.size(0)\n",
    "        accumulated_validation_loss+=loss.item()\n",
    "        if (i + 1) % 10 == 0:\n",
    "            batchwiseValAccuracyLog.append((correct / total) * 100)\n",
    "            batchwiseValLossLog.append(loss.item())\n",
    "    validation_accuracy = accumulated_validation_accuracy / total_label_count\n",
    "    epochwiseValAccuracyLog.append(validation_accuracy)\n",
    "    print('Accuracy on validation set: {}%'.format(100 * validation_accuracy))\n",
    "    epochwiseValLossLog.append(accumulated_validation_loss/inner_loop_counter_validation)\n",
    "print(\"Training Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0d38f36-4f5f-4427-82f9-52da762f1973",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot(epochs_list,epochwiseValAccuracyLog,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot()\n\u001b[0;32m----> 6\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_title\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mResNet18 Accuracy Comparisions on dataset2 with lr=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of epochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/pytorch_test/env/lib/python3.8/site-packages/matplotlib/axes/_axes.py:179\u001b[0m, in \u001b[0;36mAxes.set_title\u001b[0;34m(self, label, fontdict, loc, pad, y, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m title\u001b[38;5;241m.\u001b[39mupdate(default)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fontdict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[43mtitle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfontdict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m title\u001b[38;5;241m.\u001b[39m_internal_update(kwargs)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m title\n",
      "File \u001b[0;32m~/pytorch_test/env/lib/python3.8/site-packages/matplotlib/text.py:223\u001b[0m, in \u001b[0;36mText.update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mText\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m()  \u001b[38;5;66;03m# bbox can be None, so use another sentinel.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# Update fontproperties first, as it has lowest priority.\u001b[39;00m\n",
      "File \u001b[0;32m~/pytorch_test/env/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1781\u001b[0m, in \u001b[0;36mnormalize_kwargs\u001b[0;34m(kw, alias_mapping)\u001b[0m\n\u001b[1;32m   1778\u001b[0m canonical_to_seen \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1779\u001b[0m ret \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# output dictionary\u001b[39;00m\n\u001b[0;32m-> 1781\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mkw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m   1782\u001b[0m     canonical \u001b[38;5;241m=\u001b[39m to_canonical\u001b[38;5;241m.\u001b[39mget(k, k)\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m canonical \u001b[38;5;129;01min\u001b[39;00m canonical_to_seen:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'items'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "epochs_list = list(range(0,20))\n",
    "ax.plot(epochs_list,epochwiseTrainAccuracyLog,'g',label='Training Accuracy')\n",
    "ax.plot(epochs_list,epochwiseValAccuracyLog,'b',label='Validation Accuracy')\n",
    "ax.plot()\n",
    "ax.set_title('ResNet18 Accuracy Comparisions on dataset2 with lr='+learning_rate)\n",
    "ax.set_xlabel('Number of epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f191e27-209d-4d7b-a50b-8fc21efeb533",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(epochs_list,epochwiseTrainLossLog,'g',label='Training Loss')\n",
    "ax.plot(epochs_list,epochwiseValLossLog,'b',label='Validation Loss')\n",
    "ax.plot()\n",
    "ax.set_title('ResNet18 Loss Comparisions on dataset3 with lr=',learning_rate)\n",
    "ax.set_xlabel('Number of epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db590762-0ca7-45e5-96e0-57d6be2075c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "groundtruth = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "testAccuracyLog = []\n",
    "testLossLog = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    inner_loop_counter_test = 0\n",
    "\n",
    "    accumulated_test_accuracy=0\n",
    "    accumulated_test_loss=0\n",
    "\n",
    "    for images, labels in testingDataLoader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        inner_loop_counter_test+=1\n",
    "        test_loss=0\n",
    "        outputs = model(images)\n",
    "        test_loss=criterion(outputs,labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        y_pred.append(predicted)\n",
    "        groundtruth.append(labels)\n",
    "        accumulated_test_loss+=test_loss.item()\n",
    "    testLossLog.append(accumulated_test_loss/inner_loop_counter_test)\n",
    "    test_accuracy=correct/total\n",
    "    print('Accuracy on test set: {}%'.format(100 * test_accuracy))\n",
    "    testAccuracyLog.append(test_accuracy)\n",
    "\n",
    "predictions_np = [tensor.detach().cpu().numpy() for tensor in y_pred]\n",
    "ground_truth_np = [tensor.detach().cpu().numpy() for tensor in groundtruth]\n",
    "\n",
    "predictions_np = np.concatenate(predictions_np)\n",
    "ground_truth_np = np.concatenate(ground_truth_np)\n",
    "\n",
    "accuracy = accuracy_score(ground_truth_np, predictions_np)\n",
    "recall = recall_score(ground_truth_np, predictions_np, average='weighted')\n",
    "conf_matrix = confusion_matrix(ground_truth_np, predictions_np)\n",
    "f_score = f1_score(ground_truth_np, predictions_np, average='weighted')\n",
    "\n",
    "print(\"Dataset 2 - Test Metrics\\nAccuracy:\", accuracy*100)\n",
    "print(\"Recall:\", recall*100)\n",
    "print(\"F-score:\", f_score*100)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(conf_matrix,annot=True,fmt='d',cmap='Blues',cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix ResNet18 on Dataset2 lr',learning_rate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad1cfd-9fe5-45c4-aec4-5405e765c914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
