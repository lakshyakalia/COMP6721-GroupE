{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e03170d-dcff-4e10-a644-b950282e1cb8",
      "metadata": {
        "id": "8e03170d-dcff-4e10-a644-b950282e1cb8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "import os\n",
        "import time\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, f1_score\n",
        "from torchvision.transforms import Resize, CenterCrop, ToTensor, Normalize\n",
        "from google.colab import drive\n",
        "import pathlib\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f948234-20c4-49b2-8822-9c3a357b063b",
      "metadata": {
        "id": "2f948234-20c4-49b2-8822-9c3a357b063b"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameters\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "learning_rate = 0.01\n",
        "\n",
        "#Model Parameters\n",
        "num_features = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-0NTM8RZNo0D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0NTM8RZNo0D",
        "outputId": "d50d73b5-4624-4ac6-a606-1ce8f53d7589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "dataset_url='/content/drive/MyDrive/plant_leaf_dataset/dataset1/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af2afa0d-2cad-4aff-b7ed-6e354237aec7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af2afa0d-2cad-4aff-b7ed-6e354237aec7",
        "outputId": "0b883852-1b9d-4339-cd5e-f7c47768b0e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18936\n",
            "533\n",
            "60\n",
            "66\n"
          ]
        }
      ],
      "source": [
        "# dataset = ImageFolder(\"/content/drive/MyDrive/plant_leaf_dataset/dataset2\", transform=Compose([ToTensor(), Resize((229, 229)),CenterCrop(299),oTensor(),Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]))\n",
        "# dataset = ImageFolder(dataset_url, transform=Compose(\n",
        "#     [ToTensor(),\n",
        "#      Resize((224, 224)),\n",
        "#      Normalize(mean = [0.485, 0.456, 0.406], std =  [0.229, 0.224, 0.225])\n",
        "#     ]))\n",
        "dataset = ImageFolder(dataset_url, transform=Compose([Resize((229, 229)),CenterCrop(299),ToTensor(),Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]))\n",
        "# dataset = torch.utils.data.random_split(dataset, [100, len(dataset) - 100])\n",
        "dataset, testDataset=torch.utils.data.random_split(dataset, [int(0.9 * len(dataset)), len(dataset) - (int(0.9 * len(dataset)))])\n",
        "trainDataset, validationDataset = torch.utils.data.random_split(dataset, [int(0.9 * len(dataset)), len(dataset) - (int(0.9 * len(dataset)))])\n",
        "\n",
        "trainingDataLoader = DataLoader(\n",
        "    trainDataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validationDataLoader = DataLoader(\n",
        "    validationDataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "testingDataLoader = DataLoader(\n",
        "    testDataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(len(dataset))\n",
        "print(len(trainingDataLoader))\n",
        "print(len(validationDataLoader))\n",
        "print(len(testingDataLoader))\n",
        "\n",
        "#Write code to display the images in each dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3174e414-a18b-4fbb-b918-509568b3b263",
      "metadata": {
        "id": "3174e414-a18b-4fbb-b918-509568b3b263"
      },
      "outputs": [],
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', weights=None)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_features)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3a30437-3595-47ad-a15b-b8cef9629a1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3a30437-3595-47ad-a15b-b8cef9629a1e",
        "outputId": "9bcd2852-dbff-426d-9fb3-39d31c330db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90c69a11-0c0d-4960-ab57-0ccb74930373",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "90c69a11-0c0d-4960-ab57-0ccb74930373",
        "outputId": "d0c88383-5d42-434d-89cb-1ab7cd1d4e12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [10/533], Loss: 3.0790918, Accuracy: 6.2500%\n",
            "Epoch [1/20], Step [20/533], Loss: 3.0715976, Accuracy: 9.3750%\n",
            "Epoch [1/20], Step [30/533], Loss: 2.9172630, Accuracy: 9.3750%\n",
            "Epoch [1/20], Step [40/533], Loss: 2.9525337, Accuracy: 0.0000%\n",
            "Epoch [1/20], Step [50/533], Loss: 2.9865489, Accuracy: 9.3750%\n",
            "Epoch [1/20], Step [60/533], Loss: 3.0287452, Accuracy: 6.2500%\n",
            "Epoch [1/20], Step [70/533], Loss: 2.8601272, Accuracy: 3.1250%\n",
            "Epoch [1/20], Step [80/533], Loss: 2.9672203, Accuracy: 12.5000%\n",
            "Epoch [1/20], Step [90/533], Loss: 2.9561169, Accuracy: 18.7500%\n",
            "Epoch [1/20], Step [100/533], Loss: 2.9874160, Accuracy: 15.6250%\n",
            "Epoch [1/20], Step [110/533], Loss: 2.8429122, Accuracy: 6.2500%\n",
            "Epoch [1/20], Step [120/533], Loss: 2.8831186, Accuracy: 6.2500%\n",
            "Epoch [1/20], Step [130/533], Loss: 2.8843541, Accuracy: 9.3750%\n",
            "Epoch [1/20], Step [140/533], Loss: 3.0735531, Accuracy: 18.7500%\n",
            "Epoch [1/20], Step [150/533], Loss: 2.9300354, Accuracy: 12.5000%\n",
            "Epoch [1/20], Step [160/533], Loss: 2.7891829, Accuracy: 15.6250%\n",
            "Epoch [1/20], Step [170/533], Loss: 2.7489593, Accuracy: 18.7500%\n",
            "Epoch [1/20], Step [180/533], Loss: 2.7372949, Accuracy: 28.1250%\n",
            "Epoch [1/20], Step [190/533], Loss: 2.8588741, Accuracy: 15.6250%\n",
            "Epoch [1/20], Step [200/533], Loss: 2.7629485, Accuracy: 15.6250%\n",
            "Epoch [1/20], Step [210/533], Loss: 3.0231540, Accuracy: 15.6250%\n",
            "Epoch [1/20], Step [220/533], Loss: 2.8702106, Accuracy: 15.6250%\n",
            "Epoch [1/20], Step [230/533], Loss: 2.6986480, Accuracy: 21.8750%\n",
            "Epoch [1/20], Step [240/533], Loss: 2.8809018, Accuracy: 15.6250%\n",
            "Epoch [1/20], Step [250/533], Loss: 2.6964595, Accuracy: 9.3750%\n",
            "Epoch [1/20], Step [260/533], Loss: 2.7448137, Accuracy: 15.6250%\n",
            "Epoch [1/20], Step [270/533], Loss: 2.7989459, Accuracy: 9.3750%\n",
            "Epoch [1/20], Step [280/533], Loss: 2.6675737, Accuracy: 18.7500%\n",
            "Epoch [1/20], Step [290/533], Loss: 2.7308958, Accuracy: 18.7500%\n",
            "Epoch [1/20], Step [300/533], Loss: 2.6992669, Accuracy: 21.8750%\n",
            "Epoch [1/20], Step [310/533], Loss: 2.6655033, Accuracy: 12.5000%\n",
            "Epoch [1/20], Step [320/533], Loss: 2.6093178, Accuracy: 18.7500%\n",
            "Epoch [1/20], Step [330/533], Loss: 2.5708120, Accuracy: 21.8750%\n",
            "Epoch [1/20], Step [340/533], Loss: 2.8043258, Accuracy: 12.5000%\n"
          ]
        }
      ],
      "source": [
        "total_steps = len(trainingDataLoader)\n",
        "\n",
        "batchwiseTrainAccuracyLog = []\n",
        "batchwiseTrainLossLog = []\n",
        "\n",
        "epochwiseTrainAccuracyLog = []\n",
        "epochwiseTrainLossLog = []\n",
        "\n",
        "batchwiseValAccuracyLog = []\n",
        "batchwiseValLossLog = []\n",
        "\n",
        "epochwiseValAccuracyLog = []\n",
        "epochwiseValLossLog = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    total_label_count = 0\n",
        "\n",
        "    accumulated_train_loss=0\n",
        "    accumulated_validation_loss=0\n",
        "\n",
        "    accumulated_train_accuracy=0\n",
        "    accumulated_validation_accuracy=0\n",
        "\n",
        "    inner_loop_counter_train=0\n",
        "    model.train()\n",
        "    for i, data in enumerate(trainingDataLoader):\n",
        "        inner_loop_counter_train+=1\n",
        "\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        outputs = outputs.logits\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backprop and optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Train accuracy\n",
        "        total = labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        total_label_count += labels.size(0)\n",
        "        accumulated_train_accuracy += (predicted == labels).sum().item()\n",
        "        accumulated_train_loss+=loss.item()\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.7f}, Accuracy: {:.4f}%'\n",
        "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
        "                    (correct / total) * 100))\n",
        "            batchwiseTrainAccuracyLog.append((correct / total) * 100)\n",
        "            batchwiseTrainLossLog.append(loss.item())\n",
        "    training_accuracy = correct / total\n",
        "    epochwiseTrainAccuracyLog.append(training_accuracy)\n",
        "    print(f'EPOCH {epoch + 1}.....................')\n",
        "    print('Accuracy on training set: {}%'.format(100 * training_accuracy))\n",
        "    epochwiseTrainLossLog.append(accumulated_train_loss/inner_loop_counter_train)\n",
        "\n",
        "    #Evaluation using validation data\n",
        "\n",
        "    total_label_count = 0\n",
        "\n",
        "    inner_loop_counter_validation=0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(trainingDataLoader):\n",
        "        inner_loop_counter_validation+=1\n",
        "\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total = labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        accumulated_validation_accuracy += (predicted == labels).sum().item()\n",
        "        total_label_count += labels.size(0)\n",
        "        accumulated_validation_loss+=loss.item()\n",
        "        if (i + 1) % 10 == 0:\n",
        "            batchwiseValAccuracyLog.append((correct / total) * 100)\n",
        "            batchwiseValLossLog.append(loss.item())\n",
        "    validation_accuracy = accumulated_validation_accuracy / total_label_count\n",
        "    epochwiseValAccuracyLog.append(validation_accuracy)\n",
        "    print('Accuracy on validation set: {}%'.format(100 * validation_accuracy))\n",
        "    epochwiseValLossLog.append(accumulated_validation_loss/inner_loop_counter_validation)\n",
        "print(\"Training Finished!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0d38f36-4f5f-4427-82f9-52da762f1973",
      "metadata": {
        "id": "c0d38f36-4f5f-4427-82f9-52da762f1973"
      },
      "outputs": [],
      "source": [
        "fig,ax=plt.subplots()\n",
        "epochs_list = list(range(0,20))\n",
        "ax.plot(epochs_list,epochwiseTrainAccuracyLog,'g',label='Training Accuracy')\n",
        "ax.plot(epochs_list,epochwiseValAccuracyLog,'b',label='Validation Accuracy')\n",
        "ax.plot()\n",
        "ax.set_title('GoogLeNet Accuracy Comparisions on dataset 1 with lr=0.01')\n",
        "ax.set_xlabel('Number of epochs')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f191e27-209d-4d7b-a50b-8fc21efeb533",
      "metadata": {
        "id": "6f191e27-209d-4d7b-a50b-8fc21efeb533"
      },
      "outputs": [],
      "source": [
        "fig,ax=plt.subplots()\n",
        "ax.plot(epochs_list,epochwiseTrainLossLog,'g',label='Training Loss')\n",
        "ax.plot(epochs_list,epochwiseValLossLog,'b',label='Validation Loss')\n",
        "ax.plot()\n",
        "ax.set_title('GoogLeNet Loss Comparisions on dataset 1 with lr=0.01')\n",
        "ax.set_xlabel('Number of epochs')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db590762-0ca7-45e5-96e0-57d6be2075c9",
      "metadata": {
        "id": "db590762-0ca7-45e5-96e0-57d6be2075c9"
      },
      "outputs": [],
      "source": [
        "y_pred = []\n",
        "groundtruth = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "testAccuracyLog = []\n",
        "testLossLog = []\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    inner_loop_counter_test = 0\n",
        "\n",
        "    accumulated_test_accuracy=0\n",
        "    accumulated_test_loss=0\n",
        "\n",
        "    for images, labels in testingDataLoader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        inner_loop_counter_test+=1\n",
        "        test_loss=0\n",
        "        outputs = model(images)\n",
        "        test_loss=criterion(outputs,labels)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        y_pred.append(predicted)\n",
        "        groundtruth.append(labels)\n",
        "        accumulated_test_loss+=test_loss.item()\n",
        "    testLossLog.append(accumulated_test_loss/inner_loop_counter_test)\n",
        "    test_accuracy=correct/total\n",
        "    print('Accuracy on test set: {}%'.format(100 * test_accuracy))\n",
        "    testAccuracyLog.append(test_accuracy)\n",
        "\n",
        "predictions_np = [tensor.detach().cpu().numpy() for tensor in y_pred]\n",
        "ground_truth_np = [tensor.detach().cpu().numpy() for tensor in groundtruth]\n",
        "\n",
        "predictions_np = np.concatenate(predictions_np)\n",
        "ground_truth_np = np.concatenate(ground_truth_np)\n",
        "\n",
        "accuracy = accuracy_score(ground_truth_np, predictions_np)\n",
        "recall = recall_score(ground_truth_np, predictions_np, average='weighted')\n",
        "conf_matrix = confusion_matrix(ground_truth_np, predictions_np)\n",
        "f_score = f1_score(ground_truth_np, predictions_np, average='weighted')\n",
        "\n",
        "print(\"Dataset 1 - Test Metrics\\nAccuracy:\", accuracy*100)\n",
        "print(\"Recall:\", recall*100)\n",
        "print(\"F-score:\", f_score*100)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(conf_matrix,annot=True,fmt='d',cmap='Blues',cbar=False)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix GoogLeNet on Dataset 1 lr=0.01')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}