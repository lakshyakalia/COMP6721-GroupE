{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e03170d-dcff-4e10-a644-b950282e1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, Normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import os\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe7ec6-dd9f-4472-8693-a61e44d8cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "\n",
    "#Model Parameters\n",
    "num_features = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2afa0d-2cad-4aff-b7ed-6e354237aec7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = ImageFolder(\"/Users/karthikd1054/Documents/COMP 6721/Project/plant_leaf_dataset/dataset3\", transform=Compose(\n",
    "    [ToTensor(),\n",
    "     Resize((224, 224))\n",
    "    ]))\n",
    "dataset, testDataset=torch.utils.data.random_split(dataset, [int(0.9 * len(dataset)), len(dataset) - (int(0.9 * len(dataset)))])\n",
    "trainDataset, validationDataset = torch.utils.data.random_split(dataset, [int(0.9 * len(dataset)), len(dataset) - (int(0.9 * len(dataset)))])\n",
    "\n",
    "trainingDataLoader = DataLoader(\n",
    "    trainDataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validationDataLoader = DataLoader(\n",
    "    validationDataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "testingDataLoader = DataLoader(\n",
    "    testDataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3174e414-a18b-4fbb-b918-509568b3b263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=None)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_features)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a30437-3595-47ad-a15b-b8cef9629a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c69a11-0c0d-4960-ab57-0ccb74930373",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = len(trainingDataLoader)\n",
    "\n",
    "batchwiseTrainAccuracyLog = []\n",
    "batchwiseTrainLossLog = []\n",
    "\n",
    "epochwiseTrainAccuracyLog = []\n",
    "epochwiseTrainLossLog = []\n",
    "\n",
    "batchwiseValAccuracyLog = []\n",
    "batchwiseValLossLog = []\n",
    "\n",
    "epochwiseValAccuracyLog = []\n",
    "epochwiseValLossLog = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    total_label_count = 0\n",
    "\n",
    "    accumulated_train_loss=0\n",
    "    accumulated_validation_loss=0\n",
    "\n",
    "    accumulated_train_accuracy=0\n",
    "    accumulated_validation_accuracy=0\n",
    "\n",
    "    inner_loop_counter_train=0\n",
    "    model.train()\n",
    "    for i, data in enumerate(trainingDataLoader):\n",
    "        inner_loop_counter_train+=1\n",
    "\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backprop and optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Train accuracy\n",
    "        total = labels.size(0)\n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        total_label_count += labels.size(0)\n",
    "        accumulated_train_accuracy += (predicted == labels).sum().item()\n",
    "        accumulated_train_loss+=loss.item()\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.7f}, Accuracy: {:.4f}%'\n",
    "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
    "                    (correct / total) * 100))\n",
    "            batchwiseTrainAccuracyLog.append((correct / total) * 100)\n",
    "            batchwiseTrainLossLog.append(loss.item())\n",
    "    training_accuracy = correct / total\n",
    "    epochwiseTrainAccuracyLog.append(training_accuracy)\n",
    "    print(f'EPOCH {epoch + 1}.....................')\n",
    "    print('Accuracy on training set: {}%'.format(100 * training_accuracy))\n",
    "    epochwiseTrainLossLog.append(accumulated_train_loss/inner_loop_counter_train)\n",
    "\n",
    "    #Evaluation using validation data\n",
    "\n",
    "    total_label_count = 0\n",
    "\n",
    "    inner_loop_counter_validation=0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(trainingDataLoader):\n",
    "        inner_loop_counter_validation+=1\n",
    "\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total = labels.size(0)\n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accumulated_validation_accuracy += (predicted == labels).sum().item()\n",
    "        total_label_count += labels.size(0)\n",
    "        accumulated_validation_loss+=loss.item()\n",
    "        if (i + 1) % 10 == 0:\n",
    "            batchwiseValAccuracyLog.append((correct / total) * 100)\n",
    "            batchwiseValLossLog.append(loss.item())\n",
    "    validation_accuracy = accumulated_validation_accuracy / total_label_count\n",
    "    epochwiseValAccuracyLog.append(validation_accuracy)\n",
    "    print('Accuracy on validation set: {}%'.format(100 * validation_accuracy))\n",
    "    epochwiseValLossLog.append(accumulated_validation_loss/inner_loop_counter_validation)\n",
    "print(\"Training Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f191e27-209d-4d7b-a50b-8fc21efeb533",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "epochs_list = list(range(0,20))\n",
    "ax.plot(epochs_list,epochwiseTrainAccuracyLog,'g',label='Training Accuracy')\n",
    "ax.plot(epochs_list,epochwiseValAccuracyLog,'b',label='Validation Accuracy')\n",
    "ax.plot()\n",
    "ax.set_title('ResNet18 Accuracy Comparisions on dataset3 with lr=0.01')\n",
    "ax.set_xlabel('Number of epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5dde8-9c19-405f-bcee-d4b73683b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(epochs_list,epochwiseTrainLossLog,'g',label='Training Loss')\n",
    "ax.plot(epochs_list,epochwiseValLossLog,'b',label='Validation Loss')\n",
    "ax.plot()\n",
    "ax.set_title('ResNet18 Loss Comparisions on dataset3 with lr=0.01')\n",
    "ax.set_xlabel('Number of epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db590762-0ca7-45e5-96e0-57d6be2075c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "groundtruth = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "testAccuracyLog = []\n",
    "testLossLog = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    inner_loop_counter_test = 0\n",
    "\n",
    "    accumulated_test_accuracy=0\n",
    "    accumulated_test_loss=0\n",
    "\n",
    "    for images, labels in testingDataLoader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        inner_loop_counter_test+=1\n",
    "        test_loss=0\n",
    "        outputs = model(images)\n",
    "        test_loss=criterion(outputs,labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        y_pred.append(predicted)\n",
    "        groundtruth.append(labels)\n",
    "        accumulated_test_loss+=test_loss.item()\n",
    "    testLossLog.append(accumulated_test_loss/inner_loop_counter_test)\n",
    "    test_accuracy=correct/total\n",
    "    print('Accuracy on test set: {}%'.format(100 * test_accuracy))\n",
    "    testAccuracyLog.append(test_accuracy)\n",
    "\n",
    "predictions_np = [tensor.detach().cpu().numpy() for tensor in y_pred]\n",
    "ground_truth_np = [tensor.detach().cpu().numpy() for tensor in groundtruth]\n",
    "\n",
    "predictions_np = np.concatenate(predictions_np)\n",
    "ground_truth_np = np.concatenate(ground_truth_np)\n",
    "\n",
    "accuracy = accuracy_score(ground_truth_np, predictions_np)\n",
    "recall = recall_score(ground_truth_np, predictions_np, average='weighted')\n",
    "conf_matrix = confusion_matrix(ground_truth_np, predictions_np)\n",
    "f_score = f1_score(ground_truth_np, predictions_np, average='weighted')\n",
    "\n",
    "print(\"Dataset 3 - Test Metrics\\nAccuracy:\", accuracy*100)\n",
    "print(\"Recall:\", recall*100)\n",
    "print(\"F-score:\", f_score*100)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(conf_matrix,annot=True,fmt='d',cmap='Blues',cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix ResNet18 on Dataset3 lr=0.01')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
