{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VbuZgIypDFq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.transforms import v2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import shufflenet_v2_x0_5"
      ],
      "metadata": {
        "id": "5Jzxv27xNxj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "anuKUYvNMdjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCBnEeI_pST5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import asarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP-zMPsxB_tI"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WPUAtU5-_H-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44e49433-1e37-4db2-d20b-2356a280ece7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSgPVVUQIV5w"
      },
      "outputs": [],
      "source": [
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHMHZ9RWIJCf"
      },
      "outputs": [],
      "source": [
        "dataset_url='/content/drive/MyDrive/plant_leaf_dataset/dataset2/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diwZWM-yIjHZ"
      },
      "outputs": [],
      "source": [
        "dataset_dir=pathlib.Path(dataset_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dict={\n",
        "    'Mango': list(dataset_dir.glob('Mango (P0)/*.JPG')),\n",
        "    'Arjun': list(dataset_dir.glob('Arjun (P1)/*.JPG')),\n",
        "    'Alstonia_Scholaris': list(dataset_dir.glob('Alstonia Scholaris (P2)/*.JPG')),\n",
        "    'Gauva': list(dataset_dir.glob('Gauva (P3)/*.JPG')),\n",
        "    'Jamun': list(dataset_dir.glob('Jamun (P5)/*.JPG')),\n",
        "    'Jatropha':list(dataset_dir.glob('Jatropha (P6)/*.JPG')),\n",
        "    'Pongamia_Pinnata':list(dataset_dir.glob('Pongamia Pinnata (P7)/*.JPG')),\n",
        "    'Basil':list(dataset_dir.glob('Basil (P8)/*.JPG')),\n",
        "    'Pomegranate':list(dataset_dir.glob('Pomegranate (P9)/*.JPG')),\n",
        "    'Lemon':list(dataset_dir.glob('Lemon (P10)/*.JPG')),\n",
        "    'Chinar':list(dataset_dir.glob('Chinar (P11)/*.JPG')),\n",
        "}"
      ],
      "metadata": {
        "id": "Z-OWaBgikGid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_label_dict={\n",
        "    'Mango':0,\n",
        "    'Arjun':1,\n",
        "    'Alstonia_Scholaris':2,\n",
        "    'Gauva':3,\n",
        "    'Jamun':4,\n",
        "    'Jatropha':5,\n",
        "    'Pongamia_Pinnata':6,\n",
        "    'Basil':7,\n",
        "    'Pomegranate':8,\n",
        "    'Lemon':9,\n",
        "    'Chinar':10,\n",
        "}\n",
        "print(class_label_dict['Chinar'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbp_Wv4nvst5",
        "outputId": "ab2bb03c-6bdb-4cfd-ab73-83e8884f92e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Affine transformation to the images n+1 dimensions"
      ],
      "metadata": {
        "id": "sSMIZtiqwjth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "affine_image = v2.Compose([\n",
        "    v2.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75)),\n",
        "])\n"
      ],
      "metadata": {
        "id": "wCXMwYpVoVvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Zoom"
      ],
      "metadata": {
        "id": "km0pagm94S4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_zoom=v2.Compose([\n",
        "    v2.RandomResizedCrop(size=(224, 224))\n",
        "])"
      ],
      "metadata": {
        "id": "74h3cOfpxAQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "180 degree rotation"
      ],
      "metadata": {
        "id": "RBeVlL8S4V05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotation=v2.Compose([\n",
        "    v2.RandomRotation(degrees=(0, 180))\n",
        "])"
      ],
      "metadata": {
        "id": "38m9ZIdhzvTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resizing the images to 224 X 224 and augmenting images"
      ],
      "metadata": {
        "id": "BLUA-ZCLqY2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "y=[]\n",
        "count=0\n",
        "for key in dataset_dict.keys():\n",
        "  for values in dataset_dict[key]:\n",
        "        resized_image=Image.open(values).resize((224,224))\n",
        "        X.append(resized_image)\n",
        "        y.append(class_label_dict[key])\n",
        "        affined_image=affine_image(resized_image)\n",
        "        X.append(affined_image)\n",
        "        y.append(class_label_dict[key])\n",
        "        zoomed_image=random_zoom(resized_image)\n",
        "        X.append(zoomed_image)\n",
        "        y.append(class_label_dict[key])\n",
        "        rotated_image=rotation(resized_image)\n",
        "        X.append(rotated_image)\n",
        "        y.append(class_label_dict[key])\n",
        "        count+=1\n",
        "        if count>4:\n",
        "          break\n",
        "  break"
      ],
      "metadata": {
        "id": "eQ9t7Vi-r1M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X))\n",
        "print(len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W41rWCzkL53t",
        "outputId": "74de1d54-57bd-4489-d725-5232223cbbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image in X:\n",
        "  image=np.asarray(image)/255"
      ],
      "metadata": {
        "id": "yOHbOjSUpPag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,X_test,y_train,y_test)=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "Xjw5FHNDyYud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train),len(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs3lzD9BNIJ7",
        "outputId": "bd154fec-6e05-43e0-f46c-f8811624e6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(y[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI71YLhQovro",
        "outputId": "90b669b1-a6d8-4137-fca4-7c9841dc6b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=shufflenet_v2_x0_5()"
      ],
      "metadata": {
        "id": "sVlnbZC-NwWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_array=[]\n",
        "for _ in X_train:\n",
        "  arr=asarray(_,dtype=np.float32)/255.0\n",
        "  X_train_array.append(arr)\n",
        "X_train_tensor=torch.stack([torch.from_numpy(array) for array in X_train_array])\n",
        "\n",
        "\n",
        "# X_train_tensor=torch.tensor(X_tensor_list)\n",
        "# print(X_train_tensor.size)\n",
        "# X_train_tensor=torch.from_numpy(X_train)\n",
        "y_train_tensor=torch.tensor(y_train)"
      ],
      "metadata": {
        "id": "XGKcpJ-ZPV6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = X_train_tensor.permute(0, 3, 1, 2)"
      ],
      "metadata": {
        "id": "-fpclUtl6_YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output=model(X_train_tensor)\n",
        "classification_class=torch.argmax(output, dim=1)\n",
        "print(classification_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsxKvNLTOXqg",
        "outputId": "a7494e5f-8ecb-4a29-ae4f-da4a29afa044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([788,  41, 189,  41, 788, 189, 189, 189, 189, 189, 189, 189, 788, 189,\n",
            "        189, 189])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing ShuffleNet CNN on the pre processed dataset 2"
      ],
      "metadata": {
        "id": "1hZ_wh7BB2ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.dataset import random_split"
      ],
      "metadata": {
        "id": "L7RCKaRjBAzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define global variables:\n",
        "TOTAL_CLASSES = 11\n",
        "NUM_EPOCHS = 10\n",
        "batch_size = 32\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "VMXTCls9CS4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained googleNet Model\n",
        "# model = models.googlenet(pretrained=True)"
      ],
      "metadata": {
        "id": "Ta_a84vTCG52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading shufflenet\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfaWfUnGaQwO",
        "outputId": "96d87440-03ae-43e1-85fa-15f966718563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shufflenet defined with 1000 different classes. Need to change it with the size of our class number.\n",
        "# num_classes = TOTAL_CLASSES #len(classification_class)\n",
        "# in_features = model.fc.in_features\n",
        "# model.fc = nn.Linear(in_features, num_classes)\n"
      ],
      "metadata": {
        "id": "u8RJDBEsCQGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "z1EvVnJ0DP7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EQbS5OrnELSR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "896da822-8d4f-4e53-c1ef-e0b8fbee43c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b3217fd8f306>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making the dataset ready for taining out of x_train and y_train\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            # input_batch = image.unsqueeze(0)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Define your transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create your Dataset\n",
        "dataset = CustomDataset(images=X_train, labels=y_train, transform=transform)\n",
        "print(dataset)\n",
        "\n"
      ],
      "metadata": {
        "id": "wEPSjsa3GEUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e753a0ba-d2e1-46db-89dd-d9ef02fde50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.CustomDataset object at 0x7814eb89f430>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(dataset(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "sIB-IkZbnp85",
        "outputId": "7b9479b0-be0a-42a8-89d8-a25b0a9833b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'CustomDataset' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-f5feff92a9ed>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'CustomDataset' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class Model(torch.nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.base = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=False)\n",
        "#         self.linear1 = torch.nn.Linear(1000, 512)\n",
        "#         self.bn1 = torch.nn.BatchNorm1d(512)\n",
        "#         self.dropout1 = torch.nn.Dropout(0.5)\n",
        "#         self.linear2 = torch.nn.Linear(512, 256)\n",
        "#         self.bn2 = torch.nn.BatchNorm1d(256)\n",
        "#         self.dropout2 = torch.nn.Dropout(0.5)\n",
        "#         self.linear3 = torch.nn.Linear(256, 128)\n",
        "#         self.bn3 = torch.nn.BatchNorm1d(128)\n",
        "#         self.dropout3 = torch.nn.Dropout(0.5)\n",
        "#         self.linear4 = torch.nn.Linear(128, 104)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.base(x)\n",
        "#         x = torch.nn.ReLU()(self.linear1(x))\n",
        "#         x = self.bn1(x)\n",
        "#         if self.training:\n",
        "#             x = self.dropout1(x)\n",
        "#         x = torch.nn.ReLU()(self.linear2(x))\n",
        "#         x = self.bn2(x)\n",
        "#         if self.training:\n",
        "#             x = self.dropout2(x)\n",
        "#         x = torch.nn.ReLU()(self.linear3(x))\n",
        "#         x = self.bn3(x)\n",
        "#         if self.training:\n",
        "#             x = self.dropout3(x)\n",
        "#         x = self.linear4(x)\n",
        "\n",
        "#         return x\n",
        "\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=False)\n",
        "# model = models.shufflenet_v2_x1_0(pretrained=False)\n",
        "\n",
        "# model = Model()\n",
        "# device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = model.to(device)\n",
        "model = torch.nn.DataParallel(model)\n",
        "model.fc = nn.Linear(1024, 11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BB_LazOP_F0",
        "outputId": "394bd2eb-af73-4cb1-e35a-51733a5e3cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimize\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "QQi9BmpjR6eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Once the dataset is ready split the x_train, y_train dataset into training and validation dataset\n",
        "# 80% for training 20% for validation\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, validation_dataset = random_split(dataset, [train_size, val_size])\n",
        "print(len(train_dataset))\n",
        "print(len(validation_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zly8xH8KI9mA",
        "outputId": "ffe6683a-942d-412f-e90f-c905eabb9447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loader to feed the CNN\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "dnis_FWoJMy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the dataset\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# input_tensor = input_tensor.to('cuda')\n",
        "# tensor_on_gpu = tensor_on_gpu.to(device)\n",
        "\n",
        "# Now both tensors are on the same device, so the operation should work\n",
        "# result = torch.some_function(tensor_on_gpu, tensor_on_cpu)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print('--------------------')\n",
        "    print(f'EPOCH: {epoch + 1}/{NUM_EPOCHS}')\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        # Forward pass\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ],
      "metadata": {
        "id": "rz4Q7kaVEUqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd8bbf0-a90a-456d-e754-d3e53dbff2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            "EPOCH: 1/10\n",
            "--------------------\n",
            "EPOCH: 2/10\n",
            "--------------------\n",
            "EPOCH: 3/10\n",
            "--------------------\n",
            "EPOCH: 4/10\n",
            "--------------------\n",
            "EPOCH: 5/10\n",
            "--------------------\n",
            "EPOCH: 6/10\n",
            "--------------------\n",
            "EPOCH: 7/10\n",
            "--------------------\n",
            "EPOCH: 8/10\n",
            "--------------------\n",
            "EPOCH: 9/10\n",
            "--------------------\n",
            "EPOCH: 10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model's output\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in validation_loader:\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    # print('Accuracy on validation set: {}%'.format(100 * accuracy))\n",
        "    print(f'Accuracy {accuracy*100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWv6HNG1Eo1W",
        "outputId": "6b5360fb-e0bf-4a89-ea30-4758f6783e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 100.00%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}