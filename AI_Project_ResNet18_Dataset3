{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41jT2ObkJVKJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "import pathlib\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import time\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB7YxnXMh0_D"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameters\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "learning_rate = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNRN2efusiv-"
      },
      "outputs": [],
      "source": [
        "num_classes = 4\n",
        "def train_val_dataset(dataset, val_split=0.25):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['val'] = Subset(dataset, val_idx)\n",
        "    return datasets\n",
        "\n",
        "dataset = ImageFolder('/content/drive/MyDrive/plant_leaf_dataset/small_dataset3/', transform=Compose([Resize((224,224)),ToTensor()]))\n",
        "print(len(dataset))\n",
        "datasets = train_val_dataset(dataset)\n",
        "print(len(datasets['train']))\n",
        "print(len(datasets['val']))\n",
        "# The original dataset is available in the Subset class\n",
        "print(datasets['train'].dataset)\n",
        "valDataset = train_val_dataset(datasets['train'], 0.2)\n",
        "\n",
        "trainingDataLoader = torch.utils.data.DataLoader(\n",
        "    datasets['train'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "validationDataLoader = torch.utils.data.DataLoader(\n",
        "    valDataset['val'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "testingDataLoader = torch.utils.data.DataLoader(\n",
        "    datasets['val'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx1yXfX4KmzQ"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(trainingDataLoader))\n",
        "print(batch[0].shape)\n",
        "plt.imshow(batch[0][0].permute(2, 1, 0))\n",
        "print(batch[1][5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yptkrf1jK7a9"
      },
      "outputs": [],
      "source": [
        "model = models.resnet18(weights=None)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 20)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model = model.cuda()\n",
        "criterion = criterion.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MbK5ue0E6sP"
      },
      "outputs": [],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0VrZyXgf5FF"
      },
      "outputs": [],
      "source": [
        "epochs_list=[]\n",
        "train_loss_list=[]\n",
        "validation_loss_list=[]\n",
        "test_loss_list=[]\n",
        "training_accuracy_list=[]\n",
        "validation_accuracy_list=[]\n",
        "test_accuracy_list=[]\n",
        "\n",
        "n_total_steps = len(trainingDataLoader)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    total=0\n",
        "    correct=0\n",
        "    batch=0\n",
        "\n",
        "    accumulated_train_loss=0\n",
        "    accumulated_validation_loss=0\n",
        "    accumulated_test_loss=0\n",
        "\n",
        "    inner_loop_counter_train=0\n",
        "\n",
        "    for i, (images, labels) in enumerate(trainingDataLoader):\n",
        "        inner_loop_counter_train+=1\n",
        "        train_loss=0\n",
        "        batch+=1\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Calculate Loss\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        accumulated_train_loss+=loss\n",
        "        if (batch%10==0):\n",
        "          print(f'Loss for {batch}/{len(trainingDataLoader)} of {epoch} epochs is: ',loss)\n",
        "        # if(batch==2):\n",
        "        #   break\n",
        "    training_accuracy = correct / total\n",
        "    training_accuracy_list.append(training_accuracy)\n",
        "    print(f'EPOCH{epoch}.....................')\n",
        "    print('Accuracy on training set: {}%'.format(100 * training_accuracy))\n",
        "    train_loss_list.append(accumulated_train_loss/inner_loop_counter_train)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #Evaluation\n",
        "    inner_loop_counter_validation=0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for images, labels in validationDataLoader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        inner_loop_counter_validation+=1\n",
        "        validation_loss=0\n",
        "        outputs = model(images)\n",
        "        validation_loss=criterion(outputs,labels)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        accumulated_validation_loss+=validation_loss\n",
        "\n",
        "      validation_loss_list.append(accumulated_validation_loss/inner_loop_counter_validation)\n",
        "      validation_accuracy=correct/total\n",
        "      print(f'EPOCH{epoch}.....................')\n",
        "      print('Accuracy on validation set: {}%'.format(100 * validation_accuracy))\n",
        "      validation_accuracy_list.append(validation_accuracy)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #Testing\n",
        "    model.eval()\n",
        "    inner_loop_counter_test=0\n",
        "    with torch.no_grad():\n",
        "      for images, labels in testingDataLoader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        inner_loop_counter_test+=1\n",
        "        test_loss=0\n",
        "        outputs = model(images)\n",
        "        test_loss=criterion(outputs,labels)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        accumulated_test_loss+=test_loss\n",
        "\n",
        "      test_loss_list.append(accumulated_test_loss/inner_loop_counter_test)\n",
        "      test_accuracy=correct/total\n",
        "      print(f'EPOCH{epoch}.....................')\n",
        "      print('Accuracy on test set: {}%'.format(100 * test_accuracy))\n",
        "      test_accuracy_list.append(test_accuracy)\n",
        "    print('train loss list........',train_loss_list)\n",
        "    print('valiation loss list........',validation_loss_list)\n",
        "    print('test loss list.........',test_loss_list)\n",
        "\n",
        "print('training finished....')\n",
        "from pathlib import Path\n",
        "MODEL_PATH=Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True,exist_ok=True)\n",
        "MODEL_NAME=\"Dataset3_Google_Net.pth\"\n",
        "MODEL_SAVE_PATH=MODEL_PATH/MODEL_NAME\n",
        "print(f\"Model saving in...{MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model.state_dict(),f=MODEL_SAVE_PATH)\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPufVZIdi17k"
      },
      "outputs": [],
      "source": [
        "#Plotting Accuracy\n",
        "fig,ax=plt.subplots()\n",
        "epochs_list = list(range(0,20))\n",
        "ax.plot(epochs_list,training_accuracy_list,'g',label='Training Accuracy')\n",
        "ax.plot(epochs_list,validation_accuracy_list,'b',label='Validation Accuracy')\n",
        "ax.plot(epochs_list,test_accuracy_list,'r',label='Test Accuracy')\n",
        "ax.plot()\n",
        "ax.set_title('ResNet18')\n",
        "ax.set_xlabel('Number of epochs')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.legend()\n",
        "plt.savefig('Dataset3_ResNet18_Accuracy.png')\n",
        "files.download('Dataset3_ResNet18_Accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Plotting Loss\n",
        "fig,ax=plt.subplots()\n",
        "\n",
        "numpy_training_loss_list=[tensor.detach().cpu().numpy().astype(np.float64) for tensor in train_loss_list]\n",
        "numpy_array_training_loss= np.array(numpy_training_loss_list[1:])\n",
        "numpy_validation_loss_list=[tensor.detach().cpu().numpy().astype(np.float64) for tensor in validation_loss_list]\n",
        "numpy_array_validation_loss= np.array(numpy_validation_loss_list)\n",
        "numpy_test_loss_list=[tensor.detach().cpu().numpy().astype(np.float64) for tensor in test_loss_list]\n",
        "numpy_array_test_loss= np.array(numpy_test_loss_list)\n",
        "\n",
        "epochs_list = list(range(0,20))\n",
        "ax.plot(epochs_list[1:],numpy_array_training_loss,'g',label='Training Loss')\n",
        "epochs_list = list(range(0,21))\n",
        "ax.plot(epochs_list[1:],numpy_array_validation_loss,'b',label='Validation Loss')\n",
        "ax.plot(epochs_list[1:],numpy_array_test_loss,'r',label='Test Loss')\n",
        "ax.plot()\n",
        "ax.set_title('ResNet18')\n",
        "ax.set_xlabel('Number of epochs')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.legend()\n",
        "plt.savefig('Dataset3_ResNet18_Loss.png')\n",
        "files.download('Dataset3_ResNet18_Loss.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}